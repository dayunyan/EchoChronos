# ===============================================================================================
# The following shows the last analyze fail log message.
# ===============================================================================================

----------------------------------------------------
- Caught exception:
----------------------------------------------------
The len() only supports types such as Tensor, list, tuple, dict, scalar, and numpy ndarray, but got AbstractClass(MsClassObject: 'ModuleList').

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/ccsrc/pipeline/jit/ps/static_analysis/builtin_prim.cc:246 EvalPrim

----------------------------------------------------
- The Traceback of Net Construct Code:
----------------------------------------------------
# 0 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                               ^
# 1 In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141
        output = model(
# 2 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389
        if self.__ms_class__:
# 3 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390
            return self.forward(*args, **kwargs)
                   ^
# 4 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596
        if not isinstance(peft_config, PromptLearningConfig):
        ^
# 5 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597
            if self.base_model.config.model_type == "mpt":
            ^
# 6 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390
            return self.forward(*args, **kwargs)
                   ^
# 7 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611
            return self.base_model(
# 8 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389
        if self.__ms_class__:
# 9 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390
            return self.forward(*args, **kwargs)
                   ^
# 10 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218
        return self.model.forward(*args, **kwargs)
               ^
# 11 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767
        if not return_dict:
# 12 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738
        outputs = self.model(
# 13 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389
        if self.__ms_class__:
# 14 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390
            return self.forward(*args, **kwargs)
                   ^
# 15 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508
        if int(input_ids is None) ^ int(inputs_embeds is not None):
        ^
# 16 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:513
        if self.gradient_checkpointing and self.training:
        ^
# 17 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521
        if use_cache and not isinstance(past_key_values, Cache) and not self.training:
        ^
# 18 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390
            return self.forward(*args, **kwargs)
                   ^
# 19 In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551
        for decoder_layer in self.layers:

# ===============================================================================================
# The following shows the IR when the function graphs evaluation fails to help locate the problem.
# You can search the last ------------------------> to the node which is evaluated failure.
# Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.ir to get more instructions.
# ===============================================================================================

# IR entry: @after_grad_32
# Total subgraphs: 2

# Total params: 3
# Params:
%para1_args0 : <null>
%para2_args1 : <null>
%para3_args2 : <null>

subgraph attr:
subgraph instance: after_grad_32 : 0x165ac9800
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:588/                    def after_grad(*args):/
subgraph @after_grad_32(%para1_args0, %para2_args1, %para3_args2) {
  %1(CNode_91) = MakeTuple(%para1_args0, %para2_args1, %para3_args2)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>) -> (<Tuple[Tensor[Int64]*3], TupleShape((3, 128), (3, 128), (3, 128))>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:588/                    def after_grad(*args):/
  %2(92) = UnpackGraph(@forward_fn_3, %1)
      : (<Func, NoShape>, <Tuple[Tensor[Int64]*3], TupleShape((3, 128), (3, 128), (3, 128))>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %3(92) = S_Prim_grad(%2, (Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cf48868a-8f5a-4ea7-9d80-aa4209c6d19a), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=3403d5e0-a3a0-4ae0-bf7a-6246fcccfc10), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=95a3997d-5d33-4974-8e58-2ed8c7772738), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=c01389e8-ffa1-42eb-ba72-a6b353fbf501), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=a582a5c3-df3f-4639-b0a3-723920002b88), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=322735c8-a6eb-4334-a4e5-96be56db3f5e), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=ce6d0eee-07ad-4e60-a07b-3e833c5c43c9), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=66a674f5-7e15-44dc-a0e8-330703e58371), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f300fc01-4d2f-47ed-ba1d-509ac4700f47), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=462b40b7-e3c3-441a-93b6-33eb2c4e1155), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=eed8c72b-8c96-489f-800c-a9b21716a73f), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=2a84e491-bec4-437d-aac8-7d2fa8d77755), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=efde94a1-1de7-4716-86fc-ebcf58534b98), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=31ceaa51-c00b-4dea-9803-d91b3613baef), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=7397376c-d045-411c-9fdf-5ebdf552e9c8), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=f5794dda-7e8d-4d71-9235-4d4a80b03fac), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=a8ae9d4e-33b5-4165-9c4c-b292e93ca8fa), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=0f79c954-5a70-45ae-8fca-a7138dd7f342), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2c53efdb-bba6-4d68-8d70-4bc68cc805c2), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=ca1f052e-c204-471b-a938-068ae40cad71), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=00cc3497-b1ca-4c46-8b89-493df52fffad), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5385bcb3-dc50-490e-bdc8-4f4a7639b19d), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=b03955bb-b2fd-431e-ab24-2f2480008ffc), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=5a75bae6-d63c-41d2-99cd-66a4b4c5f524), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=d34379d6-f24f-420d-9e80-64d72a65d3c8), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=8c263007-d04c-4390-adc1-08fcc65629cd), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=8e167846-2fc1-4eb2-bb1e-887df80f4421), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=feaac602-c056-4636-97e9-0bccf1d264d6), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=10fd772a-dbce-4819-b6c9-2a22e30c0cc0), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=ac205e1d-34fe-4671-a60a-c605e6d95106), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=9ccbbd26-7370-4536-b01c-a1041a9a9c34), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=4b0c9ccf-fd79-4420-a9b7-075881003b33), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=a36f647c-250d-4ff8-9179-40dddba8d3fb), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=7652dadd-6cbe-4471-a180-002e8a1fa446), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2e2a6713-cedd-4405-9413-1f9ca0bc87f7), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=54ea7b65-84b2-4949-90b2-6a2a923bf85b), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=e59ceb48-ca5d-42b1-acd1-fb7ad559c1b4), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=24b2490f-ae89-48d4-b1f8-208e980378a4), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=4456b326-efdb-4521-ae6a-35f78b41c26e), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=95355dd6-8a4f-449a-ba60-e02af0539247), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=201b2123-63c3-4d57-97c2-f9c3cfddfc46), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=615395b1-f1b9-405e-b44b-d965ce5c21a8), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=0b3535be-86e0-4a0c-95e2-a696c7623681), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=17a618c5-e2d3-4ef3-b4cc-cae1cb3255fd), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=92a6ad9a-5248-4f99-bc2c-ecc1a3eb94a1), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=8cd565aa-1b8a-4d01-b5ad-edf171c52b04), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=4bc1909d-bf65-4f16-be27-e8852e175756), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=62304098-bf15-4631-87a0-7dee2dcb0713), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=89863bf0-0341-413a-9016-c4ceae0aef27), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=6e05a536-73f0-4423-8d3b-4e3341198f61), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=b302ae68-073d-4999-bf9a-8c658d089c38), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=3b50f48c-f568-435e-b914-3c180e71a7ae), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2cc651e7-36e9-449e-91d8-457f184d58e1), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=68567a60-2201-410d-b793-9835fceb8ce5), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cf2f2827-2e29-4b78-8520-008e29d6bdf1), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=b609a124-7eb2-493f-9478-745849a3d40a), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=994b7514-b49a-430f-a362-c7dea7d22f60), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=3cba735a-5c5c-45b1-942e-24f5880891e7), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=3e3c5d0a-920d-4dbf-8b26-3f14c94ccc93), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=7c2f30dd-cad2-4840-890b-793522b9e643), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=700636bc-6206-4188-a17b-842bfd624f9a), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5d0606c5-d5b8-42a2-b111-457b498cdc4c), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=819c9fb3-7321-4a2f-be2f-90fa4a0be56f), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=3e23bfe0-178a-4b3f-a427-ee1b5c164627), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=090c7896-171c-44d4-b12f-62f061e32b3c), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=cefb7053-fd52-4145-85d8-cb7d6732848c), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=ad556588-a9c8-4279-9b83-6034ea5a608c), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=7cd29d35-53fb-493b-a3d7-3075afb16cf6), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2244e0b9-0c18-4de8-959f-208e386fd908), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=731054c7-0b57-4fa1-abb2-925d7089301d), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2e37f6dc-b512-44da-b54b-a8a377db7740), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=42ab9db0-a43a-482e-8764-cbf9fb3500ee), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=aafb241d-e28d-464e-9e82-2b61a6f65dff), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5e021e8d-d389-4fed-b6d4-bc63ae15921e), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=af53f643-ca45-4d12-92e0-547c85fcba08), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=c2df144d-2a95-4612-8fef-1f417b9303b0), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=0cb5459b-5023-45e0-bbcf-8445a69795a5), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=cde69514-3359-47fe-90d4-0a45b5e38669), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cf69a5ea-7cc5-4855-b28c-a60752078522), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=0639b9f4-c92c-4d11-b82e-261c1b40e8cb), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=28890951-f1ea-4074-a0f9-4eb98928d3d1), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=f81b80f8-d2e1-4196-9690-143158a9b8c2), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=4e8aa6a7-b162-4fb7-bc37-62d849c51b40), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=98d81bf4-6fad-45b3-8907-e3226438bba7), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f9705ff7-9deb-45c4-8d5e-bc6e87e53ef6), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=1ce23cef-ac28-4f6c-b4c8-82b514d4cf31), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=1642ee93-5ff6-45bf-8d5a-0f5d0c04b4a0), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=185f7588-4ac3-4ee5-89d7-3995b22311d8), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=0f6de687-44c3-451c-b98a-e1fda749e4ad), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5fa3dcb7-3829-45ae-837a-2247194fca6f), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f864c8b8-37eb-433b-abbc-93d18ddcbfe8), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=5850ea90-cce8-4848-b734-1db5af75a874), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=ade0d1bf-b773-41e4-a5e8-f7e54f2cf361), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=3921887f-5122-402d-bc1c-002945dec102), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=e5a083b0-6042-448c-a818-618692f6caf6), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=d11fbd99-8a30-436e-9313-23182561580f), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f5dd4a7b-e1fd-45be-aaab-8ebafc8ffaec), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=a5d250d8-0ac3-4efa-871a-a207ea3c7437), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=131385ce-2df6-4ad4-b4a5-a3dcd4ac9f7b), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=717f09f1-8921-4baa-873f-72fcedcb0398), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f420c510-6c76-4710-a297-e6a121b11f44), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=256948ab-b52e-4a4a-8f7c-960e4a079ab3), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=c2b5f81a-06e8-467a-973f-f55a17c1717d), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=12406dbb-1456-4dd2-a8f8-5a369af33917), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=03462fc5-6fc3-43df-ba71-9f0f3d72b827), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=dc84ec93-bf62-4b29-9ff7-0f6a95a48509), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=6c9ab02e-422f-4275-951a-647da0c85c3e), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=612a32f0-46da-4e58-a84b-bd79055bb43f), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=7e056ba2-fd2a-480f-b7b3-fb5c121e1707), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=c5c6ccb2-06e2-4a9a-b123-5336b114ea1d), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=86c87b00-f927-4f2a-8709-b161a99c4d7c), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=9dead79c-6044-4dac-8774-2ea5fbc2b96c), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=e73dab31-50b4-48d0-b113-e7f7edf5d6f9), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=08ba8bdf-6255-4589-aa6b-2d1147a05bd8), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=49d6a289-2e2c-48a7-b5df-b11514353c09), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=2802233e-7648-4bd6-a313-3c001875934f), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=fb282ffd-9b99-41ed-b585-596b719b5738), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=03ce4a16-15a7-4f06-9957-56b2878d86c0), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=ec7215a7-5bd4-4499-ac9c-2f4d82ccaa9f), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=517cd47d-218c-46ad-a3ac-45faf3b90a63), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=a469ec4d-ea1e-4abf-9c5d-d81dd3357989), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=d8f27275-8b5c-40e2-9f02-feebbd4934ea), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cf31949e-49cf-4c40-8e83-1926b6fef0f4), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=13056a8a-9470-4388-a34f-a8a4ab6b6a4e), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=d44ff7c4-a958-40aa-b200-4d13b5e6177c), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=fec7a8c6-d0a7-4454-8387-7ffb4a8b02e8), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=850a9149-911f-4d8a-91bd-da242704cc64), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=7d771f2d-11d4-42d8-95fd-60f6a94cb7d5), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=320a568c-85d8-4040-baf7-bbddcac29ea4), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=d6830c1b-ac60-4a47-9663-3f833e904563), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=9a4da36c-c677-4f34-a229-acb0b66d3535), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=343a5c3b-cfae-4a68-8ac1-77ad3a3afb09), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=0e1b4e98-2fc3-444e-89eb-595a79ad78a4), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=a3042489-9d3b-4559-9295-8ae9bd887e41), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cd35bc56-51b2-46fa-abc6-bb7bd172eff7), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=2f80427e-132a-4a57-bdc9-6eb5eb1aeb0d), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=8508f032-72cf-47a6-8876-bbdee4326d0d), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5ddcba56-33df-4020-8465-51e727b24c38), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=1a151c83-b7d1-4efc-946a-261b19fbfcb2), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=1c73e492-6589-4d2d-bcfc-2bf5ca07156e), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=764aa97e-3c77-4172-a3f5-3fd7aea34600), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=0a16758a-e844-4d1f-9c46-3a4ad6af9bb3), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=b353709f-2416-4fd5-87f1-a9ecbf451c5a), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=f575e9a1-9461-413a-a95e-7008dd6b1845)))
      : (<Func, NoShape>, <Tuple[Ref[Tensor[Float32]]*144], TupleShape((8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8))>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 0
  %4(92) = UnpackCall_unpack_call(%3, %1)
      : (<Func, NoShape>, <Tuple[Tensor[Int64]*3], TupleShape((3, 128), (3, 128), (3, 128))>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @after_grad_32:92{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> forward_fn_3, [2]: CNode_91}
#   2: @after_grad_32:92{[0]: ValueNode<DoSignaturePrimitive> S_Prim_grad, [1]: 92, [2]: ValueNode<ValueTuple> (Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cf48868a-8f5a-4ea7-9d80-aa4209c6d19a), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=3403d5e0-a3a0-4ae0-bf7a-6246fcccfc10), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=95a3997d-5d33-4974-8e58-2ed8c7772738), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=c01389e8-ffa1-42eb-ba72-a6b353fbf501), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=a582a5c3-df3f-4639-b0a3-723920002b88), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=322735c8-a6eb-4334-a4e5-96be56db3f5e), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=ce6d0eee-07ad-4e60-a07b-3e833c5c43c9), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=66a674f5-7e15-44dc-a0e8-330703e58371), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f300fc01-4d2f-47ed-ba1d-509ac4700f47), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=462b40b7-e3c3-441a-93b6-33eb2c4e1155), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=eed8c72b-8c96-489f-800c-a9b21716a73f), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=2a84e491-bec4-437d-aac8-7d2fa8d77755), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=efde94a1-1de7-4716-86fc-ebcf58534b98), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=31ceaa51-c00b-4dea-9803-d91b3613baef), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=7397376c-d045-411c-9fdf-5ebdf552e9c8), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=f5794dda-7e8d-4d71-9235-4d4a80b03fac), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=a8ae9d4e-33b5-4165-9c4c-b292e93ca8fa), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=0f79c954-5a70-45ae-8fca-a7138dd7f342), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2c53efdb-bba6-4d68-8d70-4bc68cc805c2), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=ca1f052e-c204-471b-a938-068ae40cad71), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=00cc3497-b1ca-4c46-8b89-493df52fffad), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5385bcb3-dc50-490e-bdc8-4f4a7639b19d), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=b03955bb-b2fd-431e-ab24-2f2480008ffc), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=5a75bae6-d63c-41d2-99cd-66a4b4c5f524), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=d34379d6-f24f-420d-9e80-64d72a65d3c8), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=8c263007-d04c-4390-adc1-08fcc65629cd), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=8e167846-2fc1-4eb2-bb1e-887df80f4421), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=feaac602-c056-4636-97e9-0bccf1d264d6), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=10fd772a-dbce-4819-b6c9-2a22e30c0cc0), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=ac205e1d-34fe-4671-a60a-c605e6d95106), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=9ccbbd26-7370-4536-b01c-a1041a9a9c34), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=4b0c9ccf-fd79-4420-a9b7-075881003b33), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=a36f647c-250d-4ff8-9179-40dddba8d3fb), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=7652dadd-6cbe-4471-a180-002e8a1fa446), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2e2a6713-cedd-4405-9413-1f9ca0bc87f7), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=54ea7b65-84b2-4949-90b2-6a2a923bf85b), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=e59ceb48-ca5d-42b1-acd1-fb7ad559c1b4), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=24b2490f-ae89-48d4-b1f8-208e980378a4), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=4456b326-efdb-4521-ae6a-35f78b41c26e), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=95355dd6-8a4f-449a-ba60-e02af0539247), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=201b2123-63c3-4d57-97c2-f9c3cfddfc46), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=615395b1-f1b9-405e-b44b-d965ce5c21a8), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=0b3535be-86e0-4a0c-95e2-a696c7623681), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=17a618c5-e2d3-4ef3-b4cc-cae1cb3255fd), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=92a6ad9a-5248-4f99-bc2c-ecc1a3eb94a1), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=8cd565aa-1b8a-4d01-b5ad-edf171c52b04), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=4bc1909d-bf65-4f16-be27-e8852e175756), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=62304098-bf15-4631-87a0-7dee2dcb0713), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=89863bf0-0341-413a-9016-c4ceae0aef27), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=6e05a536-73f0-4423-8d3b-4e3341198f61), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=b302ae68-073d-4999-bf9a-8c658d089c38), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=3b50f48c-f568-435e-b914-3c180e71a7ae), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2cc651e7-36e9-449e-91d8-457f184d58e1), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=68567a60-2201-410d-b793-9835fceb8ce5), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cf2f2827-2e29-4b78-8520-008e29d6bdf1), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=b609a124-7eb2-493f-9478-745849a3d40a), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=994b7514-b49a-430f-a362-c7dea7d22f60), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=3cba735a-5c5c-45b1-942e-24f5880891e7), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=3e3c5d0a-920d-4dbf-8b26-3f14c94ccc93), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=7c2f30dd-cad2-4840-890b-793522b9e643), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=700636bc-6206-4188-a17b-842bfd624f9a), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5d0606c5-d5b8-42a2-b111-457b498cdc4c), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=819c9fb3-7321-4a2f-be2f-90fa4a0be56f), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=3e23bfe0-178a-4b3f-a427-ee1b5c164627), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=090c7896-171c-44d4-b12f-62f061e32b3c), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=cefb7053-fd52-4145-85d8-cb7d6732848c), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=ad556588-a9c8-4279-9b83-6034ea5a608c), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=7cd29d35-53fb-493b-a3d7-3075afb16cf6), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2244e0b9-0c18-4de8-959f-208e386fd908), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=731054c7-0b57-4fa1-abb2-925d7089301d), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=2e37f6dc-b512-44da-b54b-a8a377db7740), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=42ab9db0-a43a-482e-8764-cbf9fb3500ee), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=aafb241d-e28d-464e-9e82-2b61a6f65dff), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5e021e8d-d389-4fed-b6d4-bc63ae15921e), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=af53f643-ca45-4d12-92e0-547c85fcba08), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=c2df144d-2a95-4612-8fef-1f417b9303b0), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=0cb5459b-5023-45e0-bbcf-8445a69795a5), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=cde69514-3359-47fe-90d4-0a45b5e38669), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cf69a5ea-7cc5-4855-b28c-a60752078522), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=0639b9f4-c92c-4d11-b82e-261c1b40e8cb), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=28890951-f1ea-4074-a0f9-4eb98928d3d1), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=f81b80f8-d2e1-4196-9690-143158a9b8c2), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=4e8aa6a7-b162-4fb7-bc37-62d849c51b40), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=98d81bf4-6fad-45b3-8907-e3226438bba7), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f9705ff7-9deb-45c4-8d5e-bc6e87e53ef6), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=1ce23cef-ac28-4f6c-b4c8-82b514d4cf31), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=1642ee93-5ff6-45bf-8d5a-0f5d0c04b4a0), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=185f7588-4ac3-4ee5-89d7-3995b22311d8), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=0f6de687-44c3-451c-b98a-e1fda749e4ad), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5fa3dcb7-3829-45ae-837a-2247194fca6f), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f864c8b8-37eb-433b-abbc-93d18ddcbfe8), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=5850ea90-cce8-4848-b734-1db5af75a874), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=ade0d1bf-b773-41e4-a5e8-f7e54f2cf361), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=3921887f-5122-402d-bc1c-002945dec102), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=e5a083b0-6042-448c-a818-618692f6caf6), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=d11fbd99-8a30-436e-9313-23182561580f), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f5dd4a7b-e1fd-45be-aaab-8ebafc8ffaec), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=a5d250d8-0ac3-4efa-871a-a207ea3c7437), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=131385ce-2df6-4ad4-b4a5-a3dcd4ac9f7b), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=717f09f1-8921-4baa-873f-72fcedcb0398), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=f420c510-6c76-4710-a297-e6a121b11f44), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=256948ab-b52e-4a4a-8f7c-960e4a079ab3), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=c2b5f81a-06e8-467a-973f-f55a17c1717d), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=12406dbb-1456-4dd2-a8f8-5a369af33917), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=03462fc5-6fc3-43df-ba71-9f0f3d72b827), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=dc84ec93-bf62-4b29-9ff7-0f6a95a48509), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=6c9ab02e-422f-4275-951a-647da0c85c3e), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=612a32f0-46da-4e58-a84b-bd79055bb43f), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=7e056ba2-fd2a-480f-b7b3-fb5c121e1707), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=c5c6ccb2-06e2-4a9a-b123-5336b114ea1d), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=86c87b00-f927-4f2a-8709-b161a99c4d7c), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=9dead79c-6044-4dac-8774-2ea5fbc2b96c), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=e73dab31-50b4-48d0-b113-e7f7edf5d6f9), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=08ba8bdf-6255-4589-aa6b-2d1147a05bd8), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=49d6a289-2e2c-48a7-b5df-b11514353c09), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=2802233e-7648-4bd6-a313-3c001875934f), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=fb282ffd-9b99-41ed-b585-596b719b5738), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=03ce4a16-15a7-4f06-9957-56b2878d86c0), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=ec7215a7-5bd4-4499-ac9c-2f4d82ccaa9f), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=517cd47d-218c-46ad-a3ac-45faf3b90a63), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=a469ec4d-ea1e-4abf-9c5d-d81dd3357989), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=d8f27275-8b5c-40e2-9f02-feebbd4934ea), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cf31949e-49cf-4c40-8e83-1926b6fef0f4), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=13056a8a-9470-4388-a34f-a8a4ab6b6a4e), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=d44ff7c4-a958-40aa-b200-4d13b5e6177c), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=fec7a8c6-d0a7-4454-8387-7ffb4a8b02e8), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=850a9149-911f-4d8a-91bd-da242704cc64), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=7d771f2d-11d4-42d8-95fd-60f6a94cb7d5), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=320a568c-85d8-4040-baf7-bbddcac29ea4), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=d6830c1b-ac60-4a47-9663-3f833e904563), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=9a4da36c-c677-4f34-a229-acb0b66d3535), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=343a5c3b-cfae-4a68-8ac1-77ad3a3afb09), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=0e1b4e98-2fc3-444e-89eb-595a79ad78a4), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=a3042489-9d3b-4559-9295-8ae9bd887e41), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=cd35bc56-51b2-46fa-abc6-bb7bd172eff7), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=2f80427e-132a-4a57-bdc9-6eb5eb1aeb0d), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=8508f032-72cf-47a6-8876-bbdee4326d0d), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=5ddcba56-33df-4020-8465-51e727b24c38), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=1a151c83-b7d1-4efc-946a-261b19fbfcb2), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=1c73e492-6589-4d2d-bcfc-2bf5ca07156e), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=764aa97e-3c77-4172-a3f5-3fd7aea34600), Tensor(shape=[2048, 8], dtype=Float32, value=[...], name=0a16758a-e844-4d1f-9c46-3a4ad6af9bb3), Tensor(shape=[8, 2048], dtype=Float32, value=[...], name=b353709f-2416-4fd5-87f1-a9ecbf451c5a), Tensor(shape=[256, 8], dtype=Float32, value=[...], name=f575e9a1-9461-413a-a95e-7008dd6b1845))}
#   3: @after_grad_32:92{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.93, [1]: 92, [2]: CNode_91}
#   4: @after_grad_32:CNode_94{[0]: ValueNode<Primitive> Return, [1]: 92}


subgraph attr:
core : 1
subgraph instance: UnpackCall_33 : 0x165af0a50
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
subgraph @UnpackCall_33(%para4_, %para5_) {
  %1(92) = TupleGetItem(%para5_35, I64(0))
      : (<Tuple[Tensor[Int64]*3], TupleShape((3, 128), (3, 128), (3, 128))>, <Int64, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %2(92) = TupleGetItem(%para5_35, I64(1))
      : (<Tuple[Tensor[Int64]*3], TupleShape((3, 128), (3, 128), (3, 128))>, <Int64, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %3(92) = TupleGetItem(%para5_35, I64(2))
      : (<Tuple[Tensor[Int64]*3], TupleShape((3, 128), (3, 128), (3, 128))>, <Int64, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 1
  %4(92) = %para4_34(%1, %2, %3)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @UnpackCall_33:92{[0]: param_34, [1]: 92, [2]: 92, [3]: 92}
#   2: @UnpackCall_33:92{[0]: ValueNode<Primitive> Return, [1]: 92}


subgraph attr:
k_graph : 1
core : 1
subgraph instance: grad_forward_fn_36 : 0x165af3660
# In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:140/    def forward_fn(input_ids, attention_mask, labels):/
subgraph @grad_forward_fn_36 parent: [subgraph @grad_forward_fn_95](%para6_, %para7_, %para8_) {
  %1(92) = $(grad_forward_fn_95):J[side_effect_propagate: I64(1)](%para-1_96)
      : (<Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 2
  %2(92) = %1(%para6_grad_forward_fn, %para7_grad_forward_fn, %para8_grad_forward_fn)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %3(92) = TupleGetItem(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %4(92) = TupleGetItem(%2, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %5(92) = HyperMapPy_hyper_map[ones_like_leaf]{fn_leaf=MultitypeFuncGraph_ones_like_leaf{(NoneType), (CSRTensor), (COOTensor), (Tensor), (Func), (Number), (TypeType)}}(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %6(92) = %4(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %7(92) = TupleGetItem(%6, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %8(92) = Partial[side_effect_propagate: I64(1)](MultitypeFuncGraph_env_get{(EnvType, MapTensor), (EnvType, Tensor)}, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %9(92) = HyperMap_hyper_map(%8, %para-1_97)
      : (<null>, <Tuple[Ref[Tensor[Float32]]*144], TupleShape((8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8), (8, 2048), (2048, 8), (8, 2048), (256, 8))>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %10(92) = MakeTuple(%3, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @grad_forward_fn_36:92{[0]: 92, [1]: param_grad_forward_fn, [2]: param_grad_forward_fn, [3]: param_grad_forward_fn}
#   2: @grad_forward_fn_36:92{[0]: ValueNode<Primitive> TupleGetItem, [1]: 92, [2]: ValueNode<Int64Imm> 0}
#   3: @grad_forward_fn_36:92{[0]: ValueNode<Primitive> TupleGetItem, [1]: 92, [2]: ValueNode<Int64Imm> 1}
#   4: @grad_forward_fn_36:92{[0]: ValueNode<HyperMapPy> MetaFuncGraph-hyper_map[ones_like_leaf].98, [1]: 92}
#   5: @grad_forward_fn_36:92{[0]: 92, [1]: 92}
#   6: @grad_forward_fn_36:92{[0]: ValueNode<Primitive> TupleGetItem, [1]: 92, [2]: ValueNode<Int64Imm> 0}
#   7: @grad_forward_fn_36:92{[0]: ValueNode<Primitive> Partial, [1]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-env_get.99, [2]: 92}
#   8: @grad_forward_fn_36:92{[0]: ValueNode<HyperMap> MetaFuncGraph-hyper_map.100, [1]: 92, [2]: param_97}
#   9: @grad_forward_fn_36:92{[0]: ValueNode<Primitive> MakeTuple, [1]: 92, [2]: 92}
#  10: @grad_forward_fn_36:92{[0]: ValueNode<Primitive> Return, [1]: 92}


subgraph attr:
defer_inline : 1
subgraph instance: forward_fn_3 : 0x165ac9cc0
# In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:140/    def forward_fn(input_ids, attention_mask, labels):/
subgraph @forward_fn_3(%para9_input_ids, %para10_attention_mask, %para11_labels) {
  %1(CNode_101) = S_Prim_MakeTuple("input_ids", "attention_mask", "labels")
      : (<String, NoShape>, <String, NoShape>, <String, NoShape>) -> (<Tuple[String*3], TupleShape(NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  %2(CNode_102) = S_Prim_MakeTuple(%para9_input_ids, %para10_attention_mask, None)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <None, NoShape>) -> (<Tuple[Tensor[Int64]*2,None], TupleShape((3, 128), (3, 128), NoShape)>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  %3(CNode_103) = S_Prim_make_dict(%1, %2)
      : (<Tuple[String*3], TupleShape(NoShape, NoShape, NoShape)>, <Tuple[Tensor[Int64]*2,None], TupleShape((3, 128), (3, 128), NoShape)>) -> (<Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/

#------------------------> 3
  %4(output) = UnpackCall_unpack_call(MsClassObject, %3)
      : (<Class, NoShape>, <Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  %5(CNode_104) = getattr(%4, "logits")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:146/        loss = compute_ce_loss(output.logits, labels)/
  %6(loss) = call @compute_ce_loss_105(%5, %para11_labels)
      : (<null>, <Tensor[Int64], (3, 128)>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:146/        loss = compute_ce_loss(output.logits, labels)/
  %7(CNode_106) = getattr(%4, "logits")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:147/        return loss, output.logits/
  %8(CNode_107) = S_Prim_MakeTuple(%6, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:147/        return loss, output.logits/
  %9(CNode_108) = GradAux_aux_fn(%8, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:147/        return loss, output.logits/
}
# Order:
#   1: @forward_fn_3:CNode_101{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> input_ids, [2]: ValueNode<StringImm> attention_mask, [3]: ValueNode<StringImm> labels}
#   2: @forward_fn_3:CNode_102{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_input_ids, [2]: param_attention_mask, [3]: ValueNode<None> None}
#   3: @forward_fn_3:CNode_103{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_101, [2]: CNode_102}
#   4: @forward_fn_3:output{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.109, [1]: ValueNode<MsClassObject> MsClassObject: 'PeftModelForCausalLM', [2]: CNode_103}
#   5: @forward_fn_3:CNode_104{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> logits}
#   6: @forward_fn_3:loss{[0]: ValueNode<FuncGraph> compute_ce_loss_105, [1]: CNode_104, [2]: param_labels}
#   7: @forward_fn_3:CNode_106{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> logits}
#   8: @forward_fn_3:CNode_107{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: loss, [2]: CNode_106}
#   9: @forward_fn_3:CNode_110{[0]: ValueNode<Primitive> Return, [1]: CNode_108}
#  10: @forward_fn_3:CNode_108{[0]: ValueNode<GradAux> MetaFuncGraph-aux_fn.111, [1]: CNode_107, [2]: ValueNode<BoolImm> true}


subgraph attr:
core : 1
subgraph instance: UnpackCall_37 : 0x165b0a100
# In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
subgraph @UnpackCall_37(%para12_, %para13_) {
  %1(output) = dict_getitem(%para13_39, "input_ids")
      : (<Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  %2(output) = make_keyword_arg("input_ids", %1)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  %3(output) = dict_getitem(%para13_39, "attention_mask")
      : (<Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  %4(output) = make_keyword_arg("attention_mask", %3)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  %5(output) = dict_getitem(%para13_39, "labels")
      : (<Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  %6(output) = make_keyword_arg("labels", %5)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : labels, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/

#------------------------> 4
  %7(output) = %para12_38(%2, %4, %6)
      : (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>, <Keyword[key : labels, value : None], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:141/        output = model(/
}
# Order:
#   1: @UnpackCall_37:output{[0]: param_38, [1]: output, [2]: output, [3]: output}
#   2: @UnpackCall_37:output{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
subgraph instance: _wrapped_call_impl_40 : 0x165b16920
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
subgraph @_wrapped_call_impl_40(%para14_kwargs[input_ids], %para15_kwargs[attention_mask], %para16_kwargs[labels]) {

#------------------------> 5
  %1(CNode_112) = call @_wrapped_call_impl_41()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389/        if self.__ms_class__:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389/        if self.__ms_class__:/
}
# Order:
#   1: @_wrapped_call_impl_40:CNode_112{[0]: ValueNode<FuncGraph> _wrapped_call_impl_41}
#   2: @_wrapped_call_impl_40:CNode_113{[0]: ValueNode<Primitive> Return, [1]: CNode_112}
#   3: @_wrapped_call_impl_40:CNode_114{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.peft.peft_model..<PeftModelForCausalLM::140177700116416>', [2]: ValueNode<Symbol> forward}


subgraph attr:
subgraph instance: _wrapped_call_impl_41 : 0x165b0f950
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
subgraph @_wrapped_call_impl_41 parent: [subgraph @_wrapped_call_impl_40]() {
  %1(CNode_114) = $(_wrapped_call_impl_40):resolve(ClassMember, forward)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %2(CNode_115) = $(_wrapped_call_impl_40):MakeTuple()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %3(CNode_116) = $(_wrapped_call_impl_40):MakeTuple("input_ids", "attention_mask", "labels")
      : (<String, NoShape>, <String, NoShape>, <String, NoShape>) -> (<Tuple[String*3], TupleShape(NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %4(CNode_117) = $(_wrapped_call_impl_40):extract_keyword_arg("input_ids", %para14_kwargs[input_ids])
      : (<String, NoShape>, <Keyword[key : input_ids, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %5(CNode_118) = $(_wrapped_call_impl_40):extract_keyword_arg("attention_mask", %para15_kwargs[attention_mask])
      : (<String, NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %6(CNode_119) = $(_wrapped_call_impl_40):extract_keyword_arg("labels", %para16_kwargs[labels])
      : (<String, NoShape>, <Keyword[key : labels, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %7(CNode_120) = $(_wrapped_call_impl_40):MakeTuple(%4, %5, %6)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <None, NoShape>) -> (<Tuple[Tensor[Int64]*2,None], TupleShape((3, 128), (3, 128), NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %8(CNode_121) = $(_wrapped_call_impl_40):make_dict(%3, %7)
      : (<Tuple[String*3], TupleShape(NoShape, NoShape, NoShape)>, <Tuple[Tensor[Int64]*2,None], TupleShape((3, 128), (3, 128), NoShape)>) -> (<Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/

#------------------------> 6
  %9(CNode_122) = UnpackCall_unpack_call(%1, %2, %8)
      : (<Func, NoShape>, <Tuple[], TupleShape()>, <Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
}
# Order:
#   1: @_wrapped_call_impl_41:CNode_122{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.123, [1]: CNode_114, [2]: CNode_115, [3]: CNode_121}
#   2: @_wrapped_call_impl_41:CNode_124{[0]: ValueNode<Primitive> Return, [1]: CNode_122}


subgraph attr:
core : 1
subgraph instance: UnpackCall_42 : 0x165ba2160
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
subgraph @UnpackCall_42(%para17_, %para18_, %para19_) {
  %1(CNode_122) = dict_getitem(%para19_45, "input_ids")
      : (<Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %2(CNode_122) = make_keyword_arg("input_ids", %1)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %3(CNode_122) = dict_getitem(%para19_45, "attention_mask")
      : (<Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %4(CNode_122) = make_keyword_arg("attention_mask", %3)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %5(CNode_122) = dict_getitem(%para19_45, "labels")
      : (<Dictionary[[input_ids,attention_mask,labels,],[Tensor[Int64]*2,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %6(CNode_122) = make_keyword_arg("labels", %5)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : labels, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/

#------------------------> 7
  %7(CNode_122) = %para17_43(%2, %4, %6)
      : (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>, <Keyword[key : labels, value : None], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
}
# Order:
#   1: @UnpackCall_42:CNode_122{[0]: param_43, [1]: CNode_122, [2]: CNode_122, [3]: CNode_122}
#   2: @UnpackCall_42:CNode_122{[0]: ValueNode<Primitive> Return, [1]: CNode_122}


subgraph attr:
subgraph instance: forward_46 : 0x165bb8700
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:580/    def forward(/
subgraph @forward_46(%para20_input_ids, %para21_attention_mask, %para22_labels) {
  %1(CNode_125) = resolve(Ast, not_)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/
  %2(CNode_126) = resolve(SymbolStr, isinstance)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/
  %3(peft_config) = resolve(ClassMember, active_peft_config)
      : (<External, NoShape>, <External, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:595/        peft_config = self.active_peft_config/
  %4(CNode_127) = resolve(SymbolStr, PromptLearningConfig)
      : (<External, NoShape>, <External, NoShape>) -> (<TypeType, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/
  %5(CNode_128) = %2(%3, %4)
      : (<External, NoShape>, <TypeType, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/
  %6(CNode_129) = %1(%5)
      : (<Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/
  %7(CNode_130) = Cond(%6, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/
  %8(CNode_131) = Switch(%7, @forward_47, @forward_132)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/

#------------------------> 8
  %9(CNode_133) = %8()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:596/        if not isinstance(peft_config, PromptLearningConfig):/
}
# Order:
#   1: @forward_46:CNode_125{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> not_}
#   2: @forward_46:CNode_126{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.peft.peft_model', [2]: ValueNode<Symbol> isinstance}
#   3: @forward_46:CNode_127{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.peft.peft_model', [2]: ValueNode<Symbol> PromptLearningConfig}
#   4: @forward_134:CNode_135{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   5: @forward_134:CNode_136{[0]: CNode_135, [1]: peft_config, [2]: CNode_127}
#   6: @forward_46:CNode_128{[0]: CNode_126, [1]: peft_config, [2]: CNode_127}
#   7: @forward_46:CNode_129{[0]: CNode_125, [1]: CNode_128}
#   8: @forward_46:CNode_130{[0]: ValueNode<Primitive> Cond, [1]: CNode_129, [2]: ValueNode<BoolImm> false}
#   9: @forward_46:CNode_137{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.peft.peft_model..<PeftModelForCausalLM::140177700116416>', [2]: ValueNode<Symbol> base_model}
#  10: @forward_46:CNode_138{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.peft.peft_model', [2]: ValueNode<Symbol> PeftType}
#  11: @forward_46:CNode_131{[0]: ValueNode<Primitive> Switch, [1]: CNode_130, [2]: ValueNode<FuncGraph> forward_47, [3]: ValueNode<FuncGraph> forward_132}
#  12: @forward_46:CNode_133{[0]: CNode_131}
#  13: @forward_46:CNode_139{[0]: ValueNode<Primitive> Return, [1]: CNode_133}
#  14: @forward_46:CNode_140{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.peft.peft_model', [2]: ValueNode<Symbol> ops}
#  15: @forward_46:CNode_141{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.peft.peft_model..<PeftModelForCausalLM::140177700116416>', [2]: ValueNode<Symbol> get_prompt}
#  16: @forward_46:CNode_142{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.peft.peft_model..<PeftModelForCausalLM::140177700116416>', [2]: ValueNode<Symbol> word_embeddings}


subgraph attr:
subgraph instance: forward_47 : 0x165c3d6a0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:580/    def forward(/
subgraph @forward_47 parent: [subgraph @forward_46]() {
  %1(CNode_143) = resolve(Ast, eq)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  %2(CNode_137) = $(forward_46):resolve(ClassMember, base_model)
      : (<External, NoShape>, <External, NoShape>) -> (<Class, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  %3(CNode_144) = getattr(%2, "config")
      : (<Class, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  %4(CNode_145) = getattr(%3, "model_type")
      : (<External, NoShape>, <String, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  %5(CNode_146) = %1(%4, "mpt")
      : (<String, NoShape>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  %6(CNode_147) = Cond(%5, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  %7(CNode_148) = Switch(%6, @2forward_149, @forward_48)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/

#------------------------> 9
  %8(CNode_150) = %7()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
}
# Order:
#   1: @forward_47:CNode_145{[0]: ValueNode<Primitive> getattr, [1]: CNode_144, [2]: ValueNode<StringImm> model_type}
#   2: @forward_47:CNode_143{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> eq}
#   3: @forward_47:CNode_146{[0]: CNode_143, [1]: CNode_145, [2]: ValueNode<StringImm> mpt}
#   4: @forward_47:CNode_147{[0]: ValueNode<Primitive> Cond, [1]: CNode_146, [2]: ValueNode<BoolImm> false}
#   5: @forward_47:CNode_148{[0]: ValueNode<Primitive> Switch, [1]: CNode_147, [2]: ValueNode<FuncGraph> 2forward_149, [3]: ValueNode<FuncGraph> forward_48}
#   6: @forward_47:CNode_150{[0]: CNode_148}
#   7: @forward_47:CNode_151{[0]: ValueNode<Primitive> Return, [1]: CNode_150}
#   8: @forward_47:CNode_152{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#   9: @forward_47:CNode_153{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_144, [2]: ValueNode<StringImm> model_type}
#  10: @forward_47:CNode_154{[0]: ValueNode<Primitive> make_dict, [1]: CNode_152, [2]: CNode_153}


subgraph attr:
subgraph instance: forward_48 : 0x165c3fe00
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:580/    def forward(/
subgraph @forward_48 parent: [subgraph @forward_46]() {

#------------------------> 10
  %1(CNode_155) = call @forward_49()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
}
# Order:
#   1: @forward_48:CNode_155{[0]: ValueNode<FuncGraph> forward_49}
#   2: @forward_48:CNode_156{[0]: ValueNode<Primitive> Return, [1]: CNode_155}


subgraph attr:
after_block : 1
subgraph instance: forward_49 : 0x165c41070
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:580/    def forward(/
subgraph @forward_49 parent: [subgraph @forward_46]() {
  %1(CNode_157) = resolve(Ast, eq)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/
  %2(peft_config) = $(forward_46):resolve(ClassMember, active_peft_config)
      : (<External, NoShape>, <External, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:595/        peft_config = self.active_peft_config/
  %3(CNode_158) = getattr(%2, "peft_type")
      : (<External, NoShape>, <String, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/
  %4(CNode_138) = $(forward_46):resolve(SymbolStr, PeftType)
      : (<External, NoShape>, <External, NoShape>) -> (<TypeType, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/
  %5(CNode_159) = getattr(%4, "POLY")
      : (<TypeType, NoShape>, <String, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/
  %6(CNode_160) = %1(%3, %5)
      : (<String, NoShape>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/
  %7(CNode_161) = Cond(%6, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/
  %8(CNode_162) = Switch(%7, @forward_163, @forward_164)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/
  %9(CNode_165) = %8()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/

#------------------------> 11
  %10(CNode_166) = call @2forward_50(%9)
      : (<Dictionary[[],[]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:609/            if peft_config.peft_type == PeftType.POLY:/
}
# Order:
#   1: @forward_49:CNode_158{[0]: ValueNode<Primitive> getattr, [1]: peft_config, [2]: ValueNode<StringImm> peft_type}
#   2: @forward_49:CNode_159{[0]: ValueNode<Primitive> getattr, [1]: CNode_138, [2]: ValueNode<StringImm> POLY}
#   3: @forward_49:CNode_157{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> eq}
#   4: @forward_49:CNode_160{[0]: CNode_157, [1]: CNode_158, [2]: CNode_159}
#   5: @forward_49:CNode_161{[0]: ValueNode<Primitive> Cond, [1]: CNode_160, [2]: ValueNode<BoolImm> false}
#   6: @forward_49:CNode_162{[0]: ValueNode<Primitive> Switch, [1]: CNode_161, [2]: ValueNode<FuncGraph> forward_163, [3]: ValueNode<FuncGraph> forward_164}
#   7: @forward_49:CNode_165{[0]: CNode_162}
#   8: @forward_49:CNode_166{[0]: ValueNode<FuncGraph> 2forward_50, [1]: CNode_165}
#   9: @forward_49:CNode_167{[0]: ValueNode<Primitive> Return, [1]: CNode_166}
#  10: @forward_49:CNode_168{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  11: @forward_49:CNode_169{[0]: ValueNode<Primitive> MakeTuple, [1]: peft_config, [2]: ValueNode<StringImm> peft_type}
#  12: @forward_49:CNode_170{[0]: ValueNode<Primitive> make_dict, [1]: CNode_168, [2]: CNode_169}


subgraph attr:
after_block : 1
subgraph instance: 2forward_50 : 0x165c48b40
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:580/    def forward(/
subgraph @2forward_50 parent: [subgraph @forward_46](%para23_) {
  %1(CNode_137) = $(forward_46):resolve(ClassMember, base_model)
      : (<External, NoShape>, <External, NoShape>) -> (<Class, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:597/            if self.base_model.config.model_type == "mpt":/
  %2(CNode_171) = resolve(CommonOPS, make_dict)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %3(CNode_172) = resolve(CommonOPS, MakeTuple)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %4(CNode_173) = %3("input_ids", "attention_mask", "inputs_embeds", "labels", "output_attentions", "output_hidden_states", "return_dict")
      : (<String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>) -> (<Tuple[String*7], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %5(CNode_174) = resolve(CommonOPS, MakeTuple)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %6(CNode_175) = $(forward_46):extract_keyword_arg("input_ids", %para20_input_ids)
      : (<String, NoShape>, <Keyword[key : input_ids, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %7(CNode_176) = $(forward_46):extract_keyword_arg("attention_mask", %para21_attention_mask)
      : (<String, NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %8(CNode_177) = $(forward_46):extract_keyword_arg("labels", %para22_labels)
      : (<String, NoShape>, <Keyword[key : labels, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %9(CNode_178) = %5(%6, %7, None, %8, None, None, None)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <None, NoShape>) -> (<Tuple[Tensor[Int64]*2,None*5], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %10(CNode_179) = %2(%4, %9)
      : (<Tuple[String*7], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>, <Tuple[Tensor[Int64]*2,None*5], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape)>) -> (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/

#------------------------> 12
  %11(CNode_180) = UnpackCall_unpack_call(%1, %para23_kwargs, %10)
      : (<Class, NoShape>, <Dictionary[[],[]], NoShape>, <Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
}
# Order:
#   1: @2forward_181:self.base_model{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.peft.peft_model..<PeftModelForCausalLM::140177700116416>', [2]: ValueNode<Symbol> base_model}
#   2: @2forward_50:CNode_172{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   3: @2forward_50:CNode_173{[0]: CNode_172, [1]: ValueNode<StringImm> input_ids, [2]: ValueNode<StringImm> attention_mask, [3]: ValueNode<StringImm> inputs_embeds, [4]: ValueNode<StringImm> labels, [5]: ValueNode<StringImm> output_attentions, [6]: ValueNode<StringImm> output_hidden_states, [7]: ValueNode<StringImm> return_dict}
#   4: @2forward_50:CNode_174{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   5: @2forward_50:CNode_178{[0]: CNode_174, [1]: CNode_175, [2]: CNode_176, [3]: ValueNode<None> None, [4]: CNode_177, [5]: ValueNode<None> None, [6]: ValueNode<None> None, [7]: ValueNode<None> None}
#   6: @2forward_50:CNode_171{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> make_dict}
#   7: @2forward_50:CNode_179{[0]: CNode_171, [1]: CNode_173, [2]: CNode_178}
#   8: @2forward_50:CNode_180{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.182, [1]: CNode_137, [2]: param_kwargs, [3]: CNode_179}
#   9: @2forward_50:CNode_183{[0]: ValueNode<Primitive> Return, [1]: CNode_180}


subgraph attr:
core : 1
subgraph instance: UnpackCall_51 : 0x165d07280
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
subgraph @UnpackCall_51(%para24_, %para25_, %para26_) {
  %1(CNode_180) = dict_getitem(%para26_54, "input_ids")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %2(CNode_180) = make_keyword_arg("input_ids", %1)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %3(CNode_180) = dict_getitem(%para26_54, "attention_mask")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %4(CNode_180) = make_keyword_arg("attention_mask", %3)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %5(CNode_180) = dict_getitem(%para26_54, "inputs_embeds")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %6(CNode_180) = make_keyword_arg("inputs_embeds", %5)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : inputs_embeds, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %7(CNode_180) = dict_getitem(%para26_54, "labels")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %8(CNode_180) = make_keyword_arg("labels", %7)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : labels, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %9(CNode_180) = dict_getitem(%para26_54, "output_attentions")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %10(CNode_180) = make_keyword_arg("output_attentions", %9)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : output_attentions, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %11(CNode_180) = dict_getitem(%para26_54, "output_hidden_states")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %12(CNode_180) = make_keyword_arg("output_hidden_states", %11)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : output_hidden_states, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %13(CNode_180) = dict_getitem(%para26_54, "return_dict")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  %14(CNode_180) = make_keyword_arg("return_dict", %13)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : return_dict, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/

#------------------------> 13
  %15(CNode_180) = %para24_52(%2, %4, %6, %8, %10, %12, %14)
      : (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>, <Keyword[key : labels, value : None], NoShape>, <Keyword[key : output_attentions, value : None], NoShape>, <Keyword[key : output_hidden_states, value : None], NoShape>, <Keyword[key : return_dict, value : None], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
  Return(%15)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/peft_model.py:611/            return self.base_model(/
}
# Order:
#   1: @UnpackCall_51:CNode_180{[0]: param_52, [1]: CNode_180, [2]: CNode_180, [3]: CNode_180, [4]: CNode_180, [5]: CNode_180, [6]: CNode_180, [7]: CNode_180}
#   2: @UnpackCall_51:CNode_180{[0]: ValueNode<Primitive> Return, [1]: CNode_180}


subgraph attr:
subgraph instance: _wrapped_call_impl_55 : 0x165d17550
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
subgraph @_wrapped_call_impl_55(%para27_kwargs[input_ids], %para28_kwargs[attention_mask], %para29_kwargs[inputs_embeds], %para30_kwargs[labels], %para31_kwargs[output_attentions], %para32_kwargs[output_hidden_states], %para33_kwargs[return_dict]) {

#------------------------> 14
  %1(CNode_184) = call @_wrapped_call_impl_56()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389/        if self.__ms_class__:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389/        if self.__ms_class__:/
}
# Order:
#   1: @_wrapped_call_impl_55:CNode_184{[0]: ValueNode<FuncGraph> _wrapped_call_impl_56}
#   2: @_wrapped_call_impl_55:CNode_185{[0]: ValueNode<Primitive> Return, [1]: CNode_184}
#   3: @_wrapped_call_impl_55:CNode_186{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.peft.tuners.lora.model..<LoraModel::140177700117568>', [2]: ValueNode<Symbol> forward}


subgraph attr:
subgraph instance: _wrapped_call_impl_56 : 0x165caaee0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
subgraph @_wrapped_call_impl_56 parent: [subgraph @_wrapped_call_impl_55]() {
  %1(CNode_186) = $(_wrapped_call_impl_55):resolve(ClassMember, forward)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %2(CNode_187) = $(_wrapped_call_impl_55):MakeTuple()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %3(CNode_188) = $(_wrapped_call_impl_55):MakeTuple("input_ids", "attention_mask", "inputs_embeds", "labels", "output_attentions", "output_hidden_states", "return_dict")
      : (<String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>) -> (<Tuple[String*7], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %4(CNode_189) = $(_wrapped_call_impl_55):extract_keyword_arg("input_ids", %para27_kwargs[input_ids])
      : (<String, NoShape>, <Keyword[key : input_ids, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %5(CNode_190) = $(_wrapped_call_impl_55):extract_keyword_arg("attention_mask", %para28_kwargs[attention_mask])
      : (<String, NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %6(CNode_191) = $(_wrapped_call_impl_55):extract_keyword_arg("inputs_embeds", %para29_kwargs[inputs_embeds])
      : (<String, NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %7(CNode_192) = $(_wrapped_call_impl_55):extract_keyword_arg("labels", %para30_kwargs[labels])
      : (<String, NoShape>, <Keyword[key : labels, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %8(CNode_193) = $(_wrapped_call_impl_55):extract_keyword_arg("output_attentions", %para31_kwargs[output_attentions])
      : (<String, NoShape>, <Keyword[key : output_attentions, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %9(CNode_194) = $(_wrapped_call_impl_55):extract_keyword_arg("output_hidden_states", %para32_kwargs[output_hidden_states])
      : (<String, NoShape>, <Keyword[key : output_hidden_states, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %10(CNode_195) = $(_wrapped_call_impl_55):extract_keyword_arg("return_dict", %para33_kwargs[return_dict])
      : (<String, NoShape>, <Keyword[key : return_dict, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %11(CNode_196) = $(_wrapped_call_impl_55):MakeTuple(%4, %5, %6, %7, %8, %9, %10)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <None, NoShape>) -> (<Tuple[Tensor[Int64]*2,None*5], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %12(CNode_197) = $(_wrapped_call_impl_55):make_dict(%3, %11)
      : (<Tuple[String*7], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>, <Tuple[Tensor[Int64]*2,None*5], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape)>) -> (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/

#------------------------> 15
  %13(CNode_198) = UnpackCall_unpack_call(%1, %2, %12)
      : (<Func, NoShape>, <Tuple[], TupleShape()>, <Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%13)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
}
# Order:
#   1: @_wrapped_call_impl_56:CNode_198{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.199, [1]: CNode_186, [2]: CNode_187, [3]: CNode_197}
#   2: @_wrapped_call_impl_56:CNode_200{[0]: ValueNode<Primitive> Return, [1]: CNode_198}


subgraph attr:
core : 1
subgraph instance: UnpackCall_57 : 0x165d39a20
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
subgraph @UnpackCall_57(%para34_, %para35_, %para36_) {
  %1(CNode_198) = dict_getitem(%para36_60, "input_ids")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %2(CNode_198) = make_keyword_arg("input_ids", %1)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %3(CNode_198) = dict_getitem(%para36_60, "attention_mask")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %4(CNode_198) = make_keyword_arg("attention_mask", %3)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %5(CNode_198) = dict_getitem(%para36_60, "inputs_embeds")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %6(CNode_198) = make_keyword_arg("inputs_embeds", %5)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : inputs_embeds, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %7(CNode_198) = dict_getitem(%para36_60, "labels")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %8(CNode_198) = make_keyword_arg("labels", %7)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : labels, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %9(CNode_198) = dict_getitem(%para36_60, "output_attentions")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %10(CNode_198) = make_keyword_arg("output_attentions", %9)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : output_attentions, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %11(CNode_198) = dict_getitem(%para36_60, "output_hidden_states")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %12(CNode_198) = make_keyword_arg("output_hidden_states", %11)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : output_hidden_states, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %13(CNode_198) = dict_getitem(%para36_60, "return_dict")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %14(CNode_198) = make_keyword_arg("return_dict", %13)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : return_dict, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/

#------------------------> 16
  %15(CNode_198) = %para34_58(%2, %4, %6, %8, %10, %12, %14)
      : (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>, <Keyword[key : labels, value : None], NoShape>, <Keyword[key : output_attentions, value : None], NoShape>, <Keyword[key : output_hidden_states, value : None], NoShape>, <Keyword[key : return_dict, value : None], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%15)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
}
# Order:
#   1: @UnpackCall_57:CNode_198{[0]: param_58, [1]: CNode_198, [2]: CNode_198, [3]: CNode_198, [4]: CNode_198, [5]: CNode_198, [6]: CNode_198, [7]: CNode_198}
#   2: @UnpackCall_57:CNode_198{[0]: ValueNode<Primitive> Return, [1]: CNode_198}


subgraph attr:
subgraph instance: forward_61 : 0x165d422a0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:205/    def forward(self, *args: Any, **kwargs: Any):/
subgraph @forward_61(%para37_kwargs[input_ids], %para38_kwargs[attention_mask], %para39_kwargs[inputs_embeds], %para40_kwargs[labels], %para41_kwargs[output_attentions], %para42_kwargs[output_hidden_states], %para43_kwargs[return_dict]) {
  %1(CNode_201) = resolve(ClassMember, model)
      : (<External, NoShape>, <External, NoShape>) -> (<Class, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %2(CNode_202) = getattr(%1, "forward")
      : (<Class, NoShape>, <String, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %3(CNode_203) = MakeTuple()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:205/    def forward(self, *args: Any, **kwargs: Any):/
  %4(CNode_204) = MakeTuple("input_ids", "attention_mask", "inputs_embeds", "labels", "output_attentions", "output_hidden_states", "return_dict")
      : (<String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>) -> (<Tuple[String*7], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:205/    def forward(self, *args: Any, **kwargs: Any):/
  %5(CNode_205) = extract_keyword_arg("input_ids", %para37_kwargs[input_ids])
      : (<String, NoShape>, <Keyword[key : input_ids, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %6(CNode_206) = extract_keyword_arg("attention_mask", %para38_kwargs[attention_mask])
      : (<String, NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %7(CNode_207) = extract_keyword_arg("inputs_embeds", %para39_kwargs[inputs_embeds])
      : (<String, NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %8(CNode_208) = extract_keyword_arg("labels", %para40_kwargs[labels])
      : (<String, NoShape>, <Keyword[key : labels, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %9(CNode_209) = extract_keyword_arg("output_attentions", %para41_kwargs[output_attentions])
      : (<String, NoShape>, <Keyword[key : output_attentions, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %10(CNode_210) = extract_keyword_arg("output_hidden_states", %para42_kwargs[output_hidden_states])
      : (<String, NoShape>, <Keyword[key : output_hidden_states, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %11(CNode_211) = extract_keyword_arg("return_dict", %para43_kwargs[return_dict])
      : (<String, NoShape>, <Keyword[key : return_dict, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %12(CNode_212) = MakeTuple(%5, %6, %7, %8, %9, %10, %11)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <None, NoShape>) -> (<Tuple[Tensor[Int64]*2,None*5], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:205/    def forward(self, *args: Any, **kwargs: Any):/
  %13(CNode_213) = make_dict(%4, %12)
      : (<Tuple[String*7], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>, <Tuple[Tensor[Int64]*2,None*5], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape)>) -> (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:205/    def forward(self, *args: Any, **kwargs: Any):/

#------------------------> 17
  %14(CNode_214) = UnpackCall_unpack_call(%2, %3, %13)
      : (<Func, NoShape>, <Tuple[], TupleShape()>, <Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  Return(%14)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
}
# Order:
#   1: @forward_61:CNode_201{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.peft.tuners.lora.model..<LoraModel::140177700117568>', [2]: ValueNode<Symbol> model}
#   2: @forward_61:CNode_202{[0]: ValueNode<Primitive> getattr, [1]: CNode_201, [2]: ValueNode<StringImm> forward}
#   3: @forward_61:CNode_214{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.215, [1]: CNode_202, [2]: CNode_203, [3]: CNode_213}
#   4: @forward_61:CNode_216{[0]: ValueNode<Primitive> Return, [1]: CNode_214}


subgraph attr:
core : 1
subgraph instance: UnpackCall_62 : 0x165c93730
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
subgraph @UnpackCall_62(%para44_, %para45_, %para46_) {
  %1(CNode_214) = dict_getitem(%para46_65, "input_ids")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %2(CNode_214) = make_keyword_arg("input_ids", %1)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %3(CNode_214) = dict_getitem(%para46_65, "attention_mask")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %4(CNode_214) = make_keyword_arg("attention_mask", %3)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %5(CNode_214) = dict_getitem(%para46_65, "inputs_embeds")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %6(CNode_214) = make_keyword_arg("inputs_embeds", %5)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : inputs_embeds, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %7(CNode_214) = dict_getitem(%para46_65, "labels")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %8(CNode_214) = make_keyword_arg("labels", %7)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : labels, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %9(CNode_214) = dict_getitem(%para46_65, "output_attentions")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %10(CNode_214) = make_keyword_arg("output_attentions", %9)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : output_attentions, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %11(CNode_214) = dict_getitem(%para46_65, "output_hidden_states")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %12(CNode_214) = make_keyword_arg("output_hidden_states", %11)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : output_hidden_states, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %13(CNode_214) = dict_getitem(%para46_65, "return_dict")
      : (<Dictionary[[input_ids,attention_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,],[Tensor[Int64]*2,None*5]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  %14(CNode_214) = make_keyword_arg("return_dict", %13)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : return_dict, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/

#------------------------> 18
  %15(CNode_214) = %para44_63(%2, %4, %6, %8, %10, %12, %14)
      : (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>, <Keyword[key : labels, value : None], NoShape>, <Keyword[key : output_attentions, value : None], NoShape>, <Keyword[key : output_hidden_states, value : None], NoShape>, <Keyword[key : return_dict, value : None], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  Return(%15)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
}
# Order:
#   1: @UnpackCall_62:CNode_214{[0]: param_63, [1]: CNode_214, [2]: CNode_214, [3]: CNode_214, [4]: CNode_214, [5]: CNode_214, [6]: CNode_214, [7]: CNode_214}
#   2: @UnpackCall_62:CNode_214{[0]: ValueNode<Primitive> Return, [1]: CNode_214}


subgraph attr:
subgraph instance: forward_66 : 0x165dbcbe0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:691/    def forward(/
subgraph @forward_66(%para47_input_ids, %para48_attention_mask, %para49_inputs_embeds, %para50_labels, %para51_output_attentions, %para52_output_hidden_states, %para53_return_dict) {
  %1(CNode_217) = resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:756/        if labels is not None:/
  %2(CNode_218) = extract_keyword_arg("labels", %para50_labels)
      : (<String, NoShape>, <Keyword[key : labels, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %3(CNode_219) = %1(%2, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:756/        if labels is not None:/
  %4(CNode_220) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:756/        if labels is not None:/
  %5(CNode_221) = Switch(%4, @forward_222, @forward_223)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:756/        if labels is not None:/
  %6(CNode_224) = %5()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:756/        if labels is not None:/

#------------------------> 19
  %7(CNode_225) = call @forward_67(%6)
      : (<None, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/peft/tuners/tuners_utils.py:218/        return self.model.forward(*args, **kwargs)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:756/        if labels is not None:/
}
# Order:
#   1: @forward_66:CNode_226{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#   2: @forward_66:CNode_227{[0]: CNode_226, [1]: CNode_228, [2]: ValueNode<None> None}
#   3: @forward_66:CNode_229{[0]: ValueNode<Primitive> Cond, [1]: CNode_227, [2]: ValueNode<BoolImm> false}
#   4: @forward_66:CNode_230{[0]: ValueNode<Primitive> Switch, [1]: CNode_229, [2]: ValueNode<FuncGraph> forward_231, [3]: ValueNode<FuncGraph> forward_232}
#   5: @forward_66:output_attentions{[0]: CNode_230}
#   6: @forward_66:CNode_233{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#   7: @forward_66:CNode_234{[0]: CNode_233, [1]: CNode_235, [2]: ValueNode<None> None}
#   8: @forward_66:CNode_236{[0]: ValueNode<Primitive> Cond, [1]: CNode_234, [2]: ValueNode<BoolImm> false}
#   9: @forward_66:CNode_237{[0]: ValueNode<Primitive> Switch, [1]: CNode_236, [2]: ValueNode<FuncGraph> forward_238, [3]: ValueNode<FuncGraph> forward_239}
#  10: @forward_66:output_hidden_states{[0]: CNode_237}
#  11: @forward_66:CNode_240{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#  12: @forward_66:CNode_241{[0]: CNode_240, [1]: CNode_242, [2]: ValueNode<None> None}
#  13: @forward_66:CNode_243{[0]: ValueNode<Primitive> Cond, [1]: CNode_241, [2]: ValueNode<BoolImm> false}
#  14: @forward_66:CNode_244{[0]: ValueNode<Primitive> Switch, [1]: CNode_243, [2]: ValueNode<FuncGraph> forward_245, [3]: ValueNode<FuncGraph> forward_246}
#  15: @forward_66:return_dict{[0]: CNode_244}
#  16: @forward_66:CNode_247{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2ForCausalLM::140177264886832>', [2]: ValueNode<Symbol> model}
#  17: @forward_66:CNode_248{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#  18: @forward_66:CNode_249{[0]: CNode_248, [1]: ValueNode<StringImm> input_ids, [2]: ValueNode<StringImm> attention_mask, [3]: ValueNode<StringImm> position_ids, [4]: ValueNode<StringImm> past_key_values, [5]: ValueNode<StringImm> inputs_embeds, [6]: ValueNode<StringImm> use_cache, [7]: ValueNode<StringImm> output_attentions, [8]: ValueNode<StringImm> output_hidden_states, [9]: ValueNode<StringImm> return_dict, [10]: ValueNode<StringImm> cache_position}
#  19: @forward_66:CNode_250{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#  20: @forward_66:CNode_251{[0]: CNode_250, [1]: CNode_252, [2]: CNode_253, [3]: ValueNode<None> None, [4]: ValueNode<None> None, [5]: CNode_254, [6]: ValueNode<None> None, [7]: output_attentions, [8]: output_hidden_states, [9]: return_dict, [10]: ValueNode<None> None}
#  21: @forward_66:CNode_255{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> make_dict}
#  22: @forward_66:CNode_256{[0]: CNode_255, [1]: CNode_249, [2]: CNode_251}
#  23: @forward_66:outputs{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.257, [1]: CNode_247, [2]: CNode_256}
#  24: @forward_66:CNode_258{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> getitem}
#  25: @forward_66:hidden_states{[0]: CNode_258, [1]: outputs, [2]: ValueNode<Int64Imm> 0}
#  26: @forward_66:CNode_259{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2ForCausalLM::140177264886832>', [2]: ValueNode<Symbol> lm_head}
#  27: @forward_260:CNode_261{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#  28: @forward_260:CNode_262{[0]: CNode_261, [1]: hidden_states}
#  29: @forward_66:logits{[0]: CNode_259, [1]: hidden_states}
#  30: @forward_66:CNode_263{[0]: ValueNode<Primitive> getattr, [1]: logits, [2]: ValueNode<StringImm> float}
#  31: @forward_66:logits{[0]: CNode_263}
#  32: @forward_66:CNode_217{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#  33: @forward_66:CNode_219{[0]: CNode_217, [1]: CNode_218, [2]: ValueNode<None> None}
#  34: @forward_66:CNode_220{[0]: ValueNode<Primitive> Cond, [1]: CNode_219, [2]: ValueNode<BoolImm> false}
#  35: @forward_66:CNode_264{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> CrossEntropyLoss}
#  36: @forward_66:CNode_221{[0]: ValueNode<Primitive> Switch, [1]: CNode_220, [2]: ValueNode<FuncGraph> forward_222, [3]: ValueNode<FuncGraph> forward_223}
#  37: @forward_66:CNode_224{[0]: CNode_221}
#  38: @forward_66:CNode_225{[0]: ValueNode<FuncGraph> forward_67, [1]: CNode_224}
#  39: @forward_66:CNode_265{[0]: ValueNode<Primitive> Return, [1]: CNode_225}
#  40: @forward_66:CNode_266{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> CausalLMOutputWithPast}


subgraph attr:
after_block : 1
subgraph instance: forward_67 : 0x165cc8750
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:691/    def forward(/
subgraph @forward_67 parent: [subgraph @forward_66](%para54_) {
  %1(CNode_267) = resolve(Ast, not_)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767/        if not return_dict:/
  %2(CNode_240) = $(forward_66):resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %3(CNode_242) = $(forward_66):extract_keyword_arg("return_dict", %para53_return_dict)
      : (<String, NoShape>, <Keyword[key : return_dict, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %4(CNode_241) = $(forward_66):%2(%3, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %5(CNode_243) = $(forward_66):Cond(%4, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %6(CNode_244) = $(forward_66):Switch(%5, @forward_245, @forward_246)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %7(return_dict) = $(forward_66):%6()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %8(CNode_268) = %1(%7)
      : (<Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767/        if not return_dict:/
  %9(CNode_269) = Cond(%8, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767/        if not return_dict:/
  %10(CNode_270) = Switch(%9, @forward_271, @forward_68)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767/        if not return_dict:/

#------------------------> 20
  %11(CNode_272) = %10()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767/        if not return_dict:/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767/        if not return_dict:/
}
# Order:
#   1: @forward_67:CNode_267{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> not_}
#   2: @forward_67:CNode_268{[0]: CNode_267, [1]: return_dict}
#   3: @forward_67:CNode_269{[0]: ValueNode<Primitive> Cond, [1]: CNode_268, [2]: ValueNode<BoolImm> false}
#   4: @forward_67:CNode_270{[0]: ValueNode<Primitive> Switch, [1]: CNode_269, [2]: ValueNode<FuncGraph> forward_271, [3]: ValueNode<FuncGraph> forward_68}
#   5: @forward_67:CNode_272{[0]: CNode_270}
#   6: @forward_67:CNode_273{[0]: ValueNode<Primitive> Return, [1]: CNode_272}
#   7: @forward_274:CausalLMOutputWithPast{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> CausalLMOutputWithPast}


subgraph attr:
subgraph instance: forward_68 : 0x165ccacc0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:691/    def forward(/
subgraph @forward_68 parent: [subgraph @forward_67]() {

#------------------------> 21
  %1(CNode_275) = call @2forward_69()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767/        if not return_dict:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:767/        if not return_dict:/
}
# Order:
#   1: @forward_68:CNode_275{[0]: ValueNode<FuncGraph> 2forward_69}
#   2: @forward_68:CNode_276{[0]: ValueNode<Primitive> Return, [1]: CNode_275}


subgraph attr:
after_block : 1
subgraph instance: 2forward_69 : 0x165dbe1e0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:691/    def forward(/
subgraph @2forward_69 parent: [subgraph @forward_67]() {
  %1(CNode_266) = $(forward_66):resolve(SymbolStr, CausalLMOutputWithPast)
      : (<External, NoShape>, <External, NoShape>) -> (<TypeType, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
  %2(CNode_277) = resolve(CommonOPS, make_dict)
      : (<External, NoShape>, <External, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
  %3(CNode_278) = resolve(CommonOPS, MakeTuple)
      : (<External, NoShape>, <External, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
  %4(CNode_279) = %3("loss", "logits", "past_key_values", "hidden_states", "attentions")
      : (<String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
  %5(CNode_280) = resolve(CommonOPS, MakeTuple)
      : (<External, NoShape>, <External, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
  %6(CNode_259) = $(forward_66):resolve(ClassMember, lm_head)
      : (<External, NoShape>, <External, NoShape>) -> (<Class, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:752/        logits = self.lm_head(hidden_states)/
  %7(CNode_258) = $(forward_66):resolve(CommonOPS, getitem)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:751/        hidden_states = outputs[0]/
  %8(CNode_247) = $(forward_66):resolve(ClassMember, model)
      : (<External, NoShape>, <External, NoShape>) -> (<Class, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %9(CNode_255) = $(forward_66):resolve(CommonOPS, make_dict)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %10(CNode_248) = $(forward_66):resolve(CommonOPS, MakeTuple)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %11(CNode_249) = $(forward_66):%10("input_ids", "attention_mask", "position_ids", "past_key_values", "inputs_embeds", "use_cache", "output_attentions", "output_hidden_states", "return_dict", "cache_position")
      : (<String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>) -> (<Tuple[String*10], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %12(CNode_250) = $(forward_66):resolve(CommonOPS, MakeTuple)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %13(CNode_252) = $(forward_66):extract_keyword_arg("input_ids", %para47_input_ids)
      : (<String, NoShape>, <Keyword[key : input_ids, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %14(CNode_253) = $(forward_66):extract_keyword_arg("attention_mask", %para48_attention_mask)
      : (<String, NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %15(CNode_254) = $(forward_66):extract_keyword_arg("inputs_embeds", %para49_inputs_embeds)
      : (<String, NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %16(CNode_226) = $(forward_66):resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:731/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %17(CNode_228) = $(forward_66):extract_keyword_arg("output_attentions", %para51_output_attentions)
      : (<String, NoShape>, <Keyword[key : output_attentions, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %18(CNode_227) = $(forward_66):%16(%17, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:731/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %19(CNode_229) = $(forward_66):Cond(%18, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:731/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %20(CNode_230) = $(forward_66):Switch(%19, @forward_231, @forward_232)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:731/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %21(output_attentions) = $(forward_66):%20()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:731/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %22(CNode_233) = $(forward_66):resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:733/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %23(CNode_235) = $(forward_66):extract_keyword_arg("output_hidden_states", %para52_output_hidden_states)
      : (<String, NoShape>, <Keyword[key : output_hidden_states, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %24(CNode_234) = $(forward_66):%22(%23, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:733/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %25(CNode_236) = $(forward_66):Cond(%24, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:733/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %26(CNode_237) = $(forward_66):Switch(%25, @forward_238, @forward_239)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:733/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %27(output_hidden_states) = $(forward_66):%26()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:733/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %28(CNode_240) = $(forward_66):resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %29(CNode_242) = $(forward_66):extract_keyword_arg("return_dict", %para53_return_dict)
      : (<String, NoShape>, <Keyword[key : return_dict, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %30(CNode_241) = $(forward_66):%28(%29, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %31(CNode_243) = $(forward_66):Cond(%30, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %32(CNode_244) = $(forward_66):Switch(%31, @forward_245, @forward_246)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %33(return_dict) = $(forward_66):%32()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:735/        return_dict = return_dict if return_dict is not None else self.config.use_return_dict/
  %34(CNode_251) = $(forward_66):%12(%13, %14, None, None, %15, None, %21, %27, %33, None)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <Bool, NoShape>, <Bool, NoShape>, <Bool, NoShape>, <None, NoShape>) -> (<Tuple[Tensor[Int64]*2,None*4,Bool*3,None], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %35(CNode_256) = $(forward_66):%9(%11, %34)
      : (<Tuple[String*10], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>, <Tuple[Tensor[Int64]*2,None*4,Bool*3,None], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>) -> (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/

#------------------------> 22
  %36(outputs) = $(forward_66):UnpackCall_unpack_call(%8, %35)
      : (<Class, NoShape>, <Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %37(hidden_states) = $(forward_66):%7(%36, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:751/        hidden_states = outputs[0]/
  %38(logits) = $(forward_66):%6(%37)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:752/        logits = self.lm_head(hidden_states)/
  %39(CNode_263) = $(forward_66):getattr(%38, "float")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:753/        logits = logits.float()/
  %40(logits) = $(forward_66):%39()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:753/        logits = logits.float()/
  %41(CNode_281) = getattr(%36, "past_key_values")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:774/            past_key_values=outputs.past_key_values,/
  %42(CNode_282) = getattr(%36, "hidden_states")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:775/            hidden_states=outputs.hidden_states,/
  %43(CNode_283) = getattr(%36, "attentions")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:776/            attentions=outputs.attentions,/
  %44(CNode_284) = %5(%para54_loss, %40, %41, %42, %43)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
  %45(CNode_285) = %2(%4, %44)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
  %46(CNode_286) = UnpackCall_unpack_call(%1, %45)
      : (<TypeType, NoShape>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
  Return(%46)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:771/        return CausalLMOutputWithPast(/
}
# Order:
#   1: @2forward_69:CNode_281{[0]: ValueNode<Primitive> getattr, [1]: outputs, [2]: ValueNode<StringImm> past_key_values}
#   2: @2forward_69:CNode_282{[0]: ValueNode<Primitive> getattr, [1]: outputs, [2]: ValueNode<StringImm> hidden_states}
#   3: @2forward_69:CNode_283{[0]: ValueNode<Primitive> getattr, [1]: outputs, [2]: ValueNode<StringImm> attentions}
#   4: @2forward_69:CNode_278{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   5: @2forward_69:CNode_279{[0]: CNode_278, [1]: ValueNode<StringImm> loss, [2]: ValueNode<StringImm> logits, [3]: ValueNode<StringImm> past_key_values, [4]: ValueNode<StringImm> hidden_states, [5]: ValueNode<StringImm> attentions}
#   6: @2forward_69:CNode_280{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   7: @2forward_69:CNode_284{[0]: CNode_280, [1]: param_loss, [2]: logits, [3]: CNode_281, [4]: CNode_282, [5]: CNode_283}
#   8: @2forward_69:CNode_277{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> make_dict}
#   9: @2forward_69:CNode_285{[0]: CNode_277, [1]: CNode_279, [2]: CNode_284}
#  10: @2forward_69:CNode_286{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.287, [1]: CNode_266, [2]: CNode_285}
#  11: @2forward_69:CNode_288{[0]: ValueNode<Primitive> Return, [1]: CNode_286}


subgraph attr:
core : 1
subgraph instance: UnpackCall_70 : 0x165e7b0e0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
subgraph @UnpackCall_70(%para55_, %para56_) {
  %1(outputs) = dict_getitem(%para56_72, "input_ids")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %2(outputs) = make_keyword_arg("input_ids", %1)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %3(outputs) = dict_getitem(%para56_72, "attention_mask")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %4(outputs) = make_keyword_arg("attention_mask", %3)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %5(outputs) = dict_getitem(%para56_72, "position_ids")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %6(outputs) = make_keyword_arg("position_ids", %5)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : position_ids, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %7(outputs) = dict_getitem(%para56_72, "past_key_values")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %8(outputs) = make_keyword_arg("past_key_values", %7)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : past_key_values, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %9(outputs) = dict_getitem(%para56_72, "inputs_embeds")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %10(outputs) = make_keyword_arg("inputs_embeds", %9)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : inputs_embeds, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %11(outputs) = dict_getitem(%para56_72, "use_cache")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %12(outputs) = make_keyword_arg("use_cache", %11)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : use_cache, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %13(outputs) = dict_getitem(%para56_72, "output_attentions")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %14(outputs) = make_keyword_arg("output_attentions", %13)
      : (<String, NoShape>, <Bool, NoShape>) -> (<Keyword[key : output_attentions, value : Bool], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %15(outputs) = dict_getitem(%para56_72, "output_hidden_states")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %16(outputs) = make_keyword_arg("output_hidden_states", %15)
      : (<String, NoShape>, <Bool, NoShape>) -> (<Keyword[key : output_hidden_states, value : Bool], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %17(outputs) = dict_getitem(%para56_72, "return_dict")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %18(outputs) = make_keyword_arg("return_dict", %17)
      : (<String, NoShape>, <Bool, NoShape>) -> (<Keyword[key : return_dict, value : Bool], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %19(outputs) = dict_getitem(%para56_72, "cache_position")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  %20(outputs) = make_keyword_arg("cache_position", %19)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : cache_position, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/

#------------------------> 23
  %21(outputs) = %para55_71(%2, %4, %6, %8, %10, %12, %14, %16, %18, %20)
      : (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>, <Keyword[key : position_ids, value : None], NoShape>, <Keyword[key : past_key_values, value : None], NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>, <Keyword[key : use_cache, value : None], NoShape>, <Keyword[key : output_attentions, value : Bool], NoShape>, <Keyword[key : output_hidden_states, value : Bool], NoShape>, <Keyword[key : return_dict, value : Bool], NoShape>, <Keyword[key : cache_position, value : None], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
  Return(%21)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:738/        outputs = self.model(/
}
# Order:
#   1: @UnpackCall_70:outputs{[0]: param_71, [1]: outputs, [2]: outputs, [3]: outputs, [4]: outputs, [5]: outputs, [6]: outputs, [7]: outputs, [8]: outputs, [9]: outputs, [10]: outputs}
#   2: @UnpackCall_70:outputs{[0]: ValueNode<Primitive> Return, [1]: outputs}


subgraph attr:
subgraph instance: _wrapped_call_impl_73 : 0x165e88380
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
subgraph @_wrapped_call_impl_73(%para57_kwargs[input_ids], %para58_kwargs[attention_mask], %para59_kwargs[position_ids], %para60_kwargs[past_key_values], %para61_kwargs[inputs_embeds], %para62_kwargs[use_cache], %para63_kwargs[output_attentions], %para64_kwargs[output_hidden_states], %para65_kwargs[return_dict], %para66_kwargs[cache_position]) {

#------------------------> 24
  %1(CNode_289) = call @_wrapped_call_impl_74()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389/        if self.__ms_class__:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:389/        if self.__ms_class__:/
}
# Order:
#   1: @_wrapped_call_impl_73:CNode_289{[0]: ValueNode<FuncGraph> _wrapped_call_impl_74}
#   2: @_wrapped_call_impl_73:CNode_290{[0]: ValueNode<Primitive> Return, [1]: CNode_289}
#   3: @_wrapped_call_impl_73:CNode_291{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> forward}


subgraph attr:
subgraph instance: _wrapped_call_impl_74 : 0x165e85040
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
subgraph @_wrapped_call_impl_74 parent: [subgraph @_wrapped_call_impl_73]() {
  %1(CNode_291) = $(_wrapped_call_impl_73):resolve(ClassMember, forward)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %2(CNode_292) = $(_wrapped_call_impl_73):MakeTuple()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %3(CNode_293) = $(_wrapped_call_impl_73):MakeTuple("input_ids", "attention_mask", "position_ids", "past_key_values", "inputs_embeds", "use_cache", "output_attentions", "output_hidden_states", "return_dict", "cache_position")
      : (<String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>, <String, NoShape>) -> (<Tuple[String*10], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %4(CNode_294) = $(_wrapped_call_impl_73):extract_keyword_arg("input_ids", %para57_kwargs[input_ids])
      : (<String, NoShape>, <Keyword[key : input_ids, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %5(CNode_295) = $(_wrapped_call_impl_73):extract_keyword_arg("attention_mask", %para58_kwargs[attention_mask])
      : (<String, NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %6(CNode_296) = $(_wrapped_call_impl_73):extract_keyword_arg("position_ids", %para59_kwargs[position_ids])
      : (<String, NoShape>, <Keyword[key : position_ids, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %7(CNode_297) = $(_wrapped_call_impl_73):extract_keyword_arg("past_key_values", %para60_kwargs[past_key_values])
      : (<String, NoShape>, <Keyword[key : past_key_values, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %8(CNode_298) = $(_wrapped_call_impl_73):extract_keyword_arg("inputs_embeds", %para61_kwargs[inputs_embeds])
      : (<String, NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %9(CNode_299) = $(_wrapped_call_impl_73):extract_keyword_arg("use_cache", %para62_kwargs[use_cache])
      : (<String, NoShape>, <Keyword[key : use_cache, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %10(CNode_300) = $(_wrapped_call_impl_73):extract_keyword_arg("output_attentions", %para63_kwargs[output_attentions])
      : (<String, NoShape>, <Keyword[key : output_attentions, value : Bool], NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
  %11(CNode_301) = $(_wrapped_call_impl_73):extract_keyword_arg("output_hidden_states", %para64_kwargs[output_hidden_states])
      : (<String, NoShape>, <Keyword[key : output_hidden_states, value : Bool], NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
  %12(CNode_302) = $(_wrapped_call_impl_73):extract_keyword_arg("return_dict", %para65_kwargs[return_dict])
      : (<String, NoShape>, <Keyword[key : return_dict, value : Bool], NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
  %13(CNode_303) = $(_wrapped_call_impl_73):extract_keyword_arg("cache_position", %para66_kwargs[cache_position])
      : (<String, NoShape>, <Keyword[key : cache_position, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %14(CNode_304) = $(_wrapped_call_impl_73):MakeTuple(%4, %5, %6, %7, %8, %9, %10, %11, %12, %13)
      : (<Tensor[Int64], (3, 128)>, <Tensor[Int64], (3, 128)>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <None, NoShape>, <Bool, NoShape>, <Bool, NoShape>, <Bool, NoShape>, <None, NoShape>) -> (<Tuple[Tensor[Int64]*2,None*4,Bool*3,None], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/
  %15(CNode_305) = $(_wrapped_call_impl_73):make_dict(%3, %14)
      : (<Tuple[String*10], TupleShape(NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>, <Tuple[Tensor[Int64]*2,None*4,Bool*3,None], TupleShape((3, 128), (3, 128), NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape, NoShape)>) -> (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:388/    def _wrapped_call_impl(self, *args, **kwargs):/

#------------------------> 25
  %16(CNode_306) = UnpackCall_unpack_call(%1, %2, %15)
      : (<Func, NoShape>, <Tuple[], TupleShape()>, <Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%16)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
}
# Order:
#   1: @_wrapped_call_impl_74:CNode_306{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.307, [1]: CNode_291, [2]: CNode_292, [3]: CNode_305}
#   2: @_wrapped_call_impl_74:CNode_308{[0]: ValueNode<Primitive> Return, [1]: CNode_306}


subgraph attr:
core : 1
subgraph instance: UnpackCall_75 : 0x165ff9f40
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
subgraph @UnpackCall_75(%para67_, %para68_, %para69_) {
  %1(CNode_306) = dict_getitem(%para69_78, "input_ids")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %2(CNode_306) = make_keyword_arg("input_ids", %1)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %3(CNode_306) = dict_getitem(%para69_78, "attention_mask")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %4(CNode_306) = make_keyword_arg("attention_mask", %3)
      : (<String, NoShape>, <Tensor[Int64], (3, 128)>) -> (<Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %5(CNode_306) = dict_getitem(%para69_78, "position_ids")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %6(CNode_306) = make_keyword_arg("position_ids", %5)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : position_ids, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %7(CNode_306) = dict_getitem(%para69_78, "past_key_values")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %8(CNode_306) = make_keyword_arg("past_key_values", %7)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : past_key_values, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %9(CNode_306) = dict_getitem(%para69_78, "inputs_embeds")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %10(CNode_306) = make_keyword_arg("inputs_embeds", %9)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : inputs_embeds, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %11(CNode_306) = dict_getitem(%para69_78, "use_cache")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %12(CNode_306) = make_keyword_arg("use_cache", %11)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : use_cache, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %13(CNode_306) = dict_getitem(%para69_78, "output_attentions")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %14(CNode_306) = make_keyword_arg("output_attentions", %13)
      : (<String, NoShape>, <Bool, NoShape>) -> (<Keyword[key : output_attentions, value : Bool], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %15(CNode_306) = dict_getitem(%para69_78, "output_hidden_states")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %16(CNode_306) = make_keyword_arg("output_hidden_states", %15)
      : (<String, NoShape>, <Bool, NoShape>) -> (<Keyword[key : output_hidden_states, value : Bool], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %17(CNode_306) = dict_getitem(%para69_78, "return_dict")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %18(CNode_306) = make_keyword_arg("return_dict", %17)
      : (<String, NoShape>, <Bool, NoShape>) -> (<Keyword[key : return_dict, value : Bool], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %19(CNode_306) = dict_getitem(%para69_78, "cache_position")
      : (<Dictionary[[input_ids,attention_mask,position_ids,past_key_values,inputs_embeds,use_cache,output_attentions,output_hidden_states,return_dict,cache_position,],[Tensor[Int64]*2,None*4,Bool*3,None]], NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  %20(CNode_306) = make_keyword_arg("cache_position", %19)
      : (<String, NoShape>, <None, NoShape>) -> (<Keyword[key : cache_position, value : None], NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/

#------------------------> 26
  %21(CNode_306) = %para67_76(%2, %4, %6, %8, %10, %12, %14, %16, %18, %20)
      : (<Keyword[key : input_ids, value : Tensor[Int64]], NoShape>, <Keyword[key : attention_mask, value : Tensor[Int64]], NoShape>, <Keyword[key : position_ids, value : None], NoShape>, <Keyword[key : past_key_values, value : None], NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>, <Keyword[key : use_cache, value : None], NoShape>, <Keyword[key : output_attentions, value : Bool], NoShape>, <Keyword[key : output_hidden_states, value : Bool], NoShape>, <Keyword[key : return_dict, value : Bool], NoShape>, <Keyword[key : cache_position, value : None], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%21)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
}
# Order:
#   1: @UnpackCall_75:CNode_306{[0]: param_76, [1]: CNode_306, [2]: CNode_306, [3]: CNode_306, [4]: CNode_306, [5]: CNode_306, [6]: CNode_306, [7]: CNode_306, [8]: CNode_306, [9]: CNode_306, [10]: CNode_306}
#   2: @UnpackCall_75:CNode_306{[0]: ValueNode<Primitive> Return, [1]: CNode_306}


subgraph attr:
subgraph instance: forward_79 : 0x165fadeb0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @forward_79(%para70_input_ids, %para71_attention_mask, %para72_position_ids, %para73_past_key_values, %para74_inputs_embeds, %para75_use_cache, %para76_output_attentions, %para77_output_hidden_states, %para78_return_dict, %para79_cache_position) {
  %1(CNode_309) = resolve(Ast, xor)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %2(CNode_310) = resolve(SymbolStr, int)
      : (<External, NoShape>, <External, NoShape>) -> (<TypeType, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %3(CNode_311) = resolve(Ast, is_)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %4(CNode_312) = extract_keyword_arg("input_ids", %para70_input_ids)
      : (<String, NoShape>, <Keyword[key : input_ids, value : Tensor[Int64]], NoShape>) -> (<Tensor[Int64], (3, 128)>)
      #scope: (Default)
  %5(CNode_313) = %3(%4, None)
      : (<Tensor[Int64], (3, 128)>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %6(CNode_314) = %2(%5)
      : (<Bool, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %7(CNode_315) = resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %8(CNode_316) = extract_keyword_arg("inputs_embeds", %para74_inputs_embeds)
      : (<String, NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %9(CNode_317) = %7(%8, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %10(CNode_318) = %2(%9)
      : (<Bool, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %11(CNode_319) = %1(%6, %10)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %12(CNode_320) = Cond(%11, Bool(0))
      : (<Int64, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  %13(CNode_321) = Switch(%12, @forward_322, @forward_80)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/

#------------------------> 27
  %14(CNode_323) = %13()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  Return(%14)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
}
# Order:
#   1: @forward_79:CNode_324{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#   2: @forward_79:CNode_325{[0]: CNode_324, [1]: CNode_326, [2]: ValueNode<None> None}
#   3: @forward_79:CNode_327{[0]: ValueNode<Primitive> Cond, [1]: CNode_325, [2]: ValueNode<BoolImm> false}
#   4: @forward_79:CNode_328{[0]: ValueNode<Primitive> Switch, [1]: CNode_327, [2]: ValueNode<FuncGraph> forward_329, [3]: ValueNode<FuncGraph> forward_330}
#   5: @forward_79:output_attentions{[0]: CNode_328}
#   6: @forward_79:CNode_331{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#   7: @forward_79:CNode_332{[0]: CNode_331, [1]: CNode_333, [2]: ValueNode<None> None}
#   8: @forward_79:CNode_334{[0]: ValueNode<Primitive> Cond, [1]: CNode_332, [2]: ValueNode<BoolImm> false}
#   9: @forward_79:CNode_335{[0]: ValueNode<Primitive> Switch, [1]: CNode_334, [2]: ValueNode<FuncGraph> forward_336, [3]: ValueNode<FuncGraph> forward_337}
#  10: @forward_79:output_hidden_states{[0]: CNode_335}
#  11: @forward_79:CNode_338{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#  12: @forward_79:CNode_339{[0]: CNode_338, [1]: CNode_340, [2]: ValueNode<None> None}
#  13: @forward_79:CNode_341{[0]: ValueNode<Primitive> Cond, [1]: CNode_339, [2]: ValueNode<BoolImm> false}
#  14: @forward_79:CNode_342{[0]: ValueNode<Primitive> Switch, [1]: CNode_341, [2]: ValueNode<FuncGraph> forward_343, [3]: ValueNode<FuncGraph> forward_344}
#  15: @forward_79:use_cache{[0]: CNode_342}
#  16: @forward_79:CNode_345{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#  17: @forward_79:CNode_346{[0]: CNode_345, [1]: CNode_347, [2]: ValueNode<None> None}
#  18: @forward_79:CNode_348{[0]: ValueNode<Primitive> Cond, [1]: CNode_346, [2]: ValueNode<BoolImm> false}
#  19: @forward_79:CNode_349{[0]: ValueNode<Primitive> Switch, [1]: CNode_348, [2]: ValueNode<FuncGraph> forward_350, [3]: ValueNode<FuncGraph> forward_351}
#  20: @forward_79:return_dict{[0]: CNode_349}
#  21: @forward_79:CNode_310{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> int}
#  22: @forward_79:CNode_311{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_}
#  23: @forward_79:CNode_313{[0]: CNode_311, [1]: CNode_312, [2]: ValueNode<None> None}
#  24: @forward_352:CNode_353{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#  25: @forward_352:CNode_354{[0]: CNode_353, [1]: CNode_313}
#  26: @forward_79:CNode_314{[0]: CNode_310, [1]: CNode_313}
#  27: @forward_79:CNode_315{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_not}
#  28: @forward_79:CNode_317{[0]: CNode_315, [1]: CNode_316, [2]: ValueNode<None> None}
#  29: @forward_352:CNode_355{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#  30: @forward_352:CNode_356{[0]: CNode_355, [1]: CNode_317}
#  31: @forward_79:CNode_318{[0]: CNode_310, [1]: CNode_317}
#  32: @forward_79:CNode_309{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> xor}
#  33: @forward_79:CNode_319{[0]: CNode_309, [1]: CNode_314, [2]: CNode_318}
#  34: @forward_79:CNode_320{[0]: ValueNode<Primitive> Cond, [1]: CNode_319, [2]: ValueNode<BoolImm> false}
#  35: @forward_79:CNode_321{[0]: ValueNode<Primitive> Switch, [1]: CNode_320, [2]: ValueNode<FuncGraph> forward_322, [3]: ValueNode<FuncGraph> forward_80}
#  36: @forward_79:CNode_323{[0]: CNode_321}
#  37: @forward_79:CNode_357{[0]: ValueNode<Primitive> Return, [1]: CNode_323}
#  38: @forward_79:CNode_358{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> isinstance}
#  39: @forward_79:CNode_359{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> Cache}
#  40: @forward_79:CNode_360{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> DynamicCache}
#  41: @forward_79:CNode_361{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> logger}
#  42: @forward_79:CNode_362{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> embed_tokens}
#  43: @forward_79:CNode_363{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> ops}
#  44: @forward_79:CNode_364{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> _update_causal_mask}
#  45: @forward_79:CNode_365{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> layers}
#  46: @forward_79:CNode_366{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> norm}
#  47: @forward_79:CNode_367{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> tuple}
#  48: @forward_79:CNode_368{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> BaseModelOutputWithPast}


subgraph attr:
subgraph instance: forward_80 : 0x165fe4930
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @forward_80 parent: [subgraph @forward_79]() {

#------------------------> 28
  %1(CNode_369) = call @forward_81()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:508/        if int(input_ids is None) ^ int(inputs_embeds is not None):/
}
# Order:
#   1: @forward_80:CNode_369{[0]: ValueNode<FuncGraph> forward_81}
#   2: @forward_80:CNode_370{[0]: ValueNode<Primitive> Return, [1]: CNode_369}


subgraph attr:
after_block : 1
subgraph instance: forward_81 : 0x165fee050
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @forward_81 parent: [subgraph @forward_79]() {

#------------------------> 29
  %1(CNode_371) = call @forward_82()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:513/        if self.gradient_checkpointing and self.training:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:513/        if self.gradient_checkpointing and self.training:/
}
# Order:
#   1: @forward_81:CNode_371{[0]: ValueNode<FuncGraph> forward_82}
#   2: @forward_81:CNode_372{[0]: ValueNode<Primitive> Return, [1]: CNode_371}


subgraph attr:
subgraph instance: forward_82 : 0x165fd8d70
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @forward_82 parent: [subgraph @forward_79]() {

#------------------------> 30
  %1(CNode_373) = call @2forward_83()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:513/        if self.gradient_checkpointing and self.training:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:513/        if self.gradient_checkpointing and self.training:/
}
# Order:
#   1: @forward_82:CNode_373{[0]: ValueNode<FuncGraph> 2forward_83}
#   2: @forward_82:CNode_374{[0]: ValueNode<Primitive> Return, [1]: CNode_373}


subgraph attr:
subgraph instance: 2forward_83 : 0x1660216a0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @2forward_83 parent: [subgraph @forward_79]() {
  %1(CNode_338) = $(forward_79):resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:504/        use_cache = use_cache if use_cache is not None else self.config.use_cache/
  %2(CNode_340) = $(forward_79):extract_keyword_arg("use_cache", %para75_use_cache)
      : (<String, NoShape>, <Keyword[key : use_cache, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %3(CNode_339) = $(forward_79):%1(%2, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:504/        use_cache = use_cache if use_cache is not None else self.config.use_cache/
  %4(CNode_341) = $(forward_79):Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:504/        use_cache = use_cache if use_cache is not None else self.config.use_cache/
  %5(CNode_342) = $(forward_79):Switch(%4, @forward_343, @forward_344)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:504/        use_cache = use_cache if use_cache is not None else self.config.use_cache/
  %6(use_cache) = $(forward_79):%5()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:504/        use_cache = use_cache if use_cache is not None else self.config.use_cache/
  %7(CNode_375) = Cond(%6, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521/        if use_cache and not isinstance(past_key_values, Cache) and not self.training:/
  %8(CNode_376) = Switch(%7, @2forward_377, @2forward_378)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521/        if use_cache and not isinstance(past_key_values, Cache) and not self.training:/
  %9(CNode_379) = %8()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521/        if use_cache and not isinstance(past_key_values, Cache) and not self.training:/
  %10(CNode_380) = Cond(%9, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521/        if use_cache and not isinstance(past_key_values, Cache) and not self.training:/
  %11(CNode_381) = Switch(%10, @2forward_382, @2forward_84)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521/        if use_cache and not isinstance(past_key_values, Cache) and not self.training:/

#------------------------> 31
  %12(CNode_383) = %11()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521/        if use_cache and not isinstance(past_key_values, Cache) and not self.training:/
  Return(%12)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521/        if use_cache and not isinstance(past_key_values, Cache) and not self.training:/
}
# Order:
#   1: @2forward_83:CNode_375{[0]: ValueNode<Primitive> Cond, [1]: use_cache, [2]: ValueNode<BoolImm> false}
#   2: @2forward_83:CNode_376{[0]: ValueNode<Primitive> Switch, [1]: CNode_375, [2]: ValueNode<FuncGraph> 2forward_377, [3]: ValueNode<FuncGraph> 2forward_378}
#   3: @2forward_83:CNode_379{[0]: CNode_376}
#   4: @2forward_83:CNode_380{[0]: ValueNode<Primitive> Cond, [1]: CNode_379, [2]: ValueNode<BoolImm> false}
#   5: @2forward_83:CNode_381{[0]: ValueNode<Primitive> Switch, [1]: CNode_380, [2]: ValueNode<FuncGraph> 2forward_382, [3]: ValueNode<FuncGraph> 2forward_84}
#   6: @2forward_83:CNode_383{[0]: CNode_381}
#   7: @2forward_83:CNode_384{[0]: ValueNode<Primitive> Return, [1]: CNode_383}


subgraph attr:
subgraph instance: 2forward_84 : 0x165f59890
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @2forward_84 parent: [subgraph @forward_79]() {
  %1(CNode_385) = $(forward_79):extract_keyword_arg("past_key_values", %para73_past_key_values)
      : (<String, NoShape>, <Keyword[key : past_key_values, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)

#------------------------> 32
  %2(CNode_386) = call @3forward_85(%1, Bool(0))
      : (<None, NoShape>, <Bool, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:521/        if use_cache and not isinstance(past_key_values, Cache) and not self.training:/
}
# Order:
#   1: @2forward_84:CNode_387{[0]: ValueNode<Primitive> Return, [1]: CNode_386}
#   2: @2forward_84:CNode_386{[0]: ValueNode<FuncGraph> 3forward_85, [1]: CNode_385, [2]: ValueNode<BoolImm> false}


subgraph attr:
after_block : 1
subgraph instance: 3forward_85 : 0x165fd1470
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @3forward_85 parent: [subgraph @forward_79](%para80_, %para81_) {
  %1(CNode_388) = resolve(Ast, is_)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:529/        if inputs_embeds is None:/
  %2(CNode_316) = $(forward_79):extract_keyword_arg("inputs_embeds", %para74_inputs_embeds)
      : (<String, NoShape>, <Keyword[key : inputs_embeds, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %3(CNode_389) = %1(%2, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:529/        if inputs_embeds is None:/
  %4(CNode_390) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:529/        if inputs_embeds is None:/
  %5(CNode_391) = Switch(%4, @3forward_392, @3forward_393)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:529/        if inputs_embeds is None:/
  %6(CNode_394) = %5()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:529/        if inputs_embeds is None:/

#------------------------> 33
  %7(CNode_395) = call @4forward_86(%6)
      : (<Tensor[Float32], (3, 128, 2048)>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:529/        if inputs_embeds is None:/
}
# Order:
#   1: @3forward_85:CNode_388{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_}
#   2: @3forward_85:CNode_389{[0]: CNode_388, [1]: CNode_316, [2]: ValueNode<None> None}
#   3: @3forward_85:CNode_390{[0]: ValueNode<Primitive> Cond, [1]: CNode_389, [2]: ValueNode<BoolImm> false}
#   4: @3forward_396:self.embed_tokens{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> embed_tokens}
#   5: @3forward_85:CNode_391{[0]: ValueNode<Primitive> Switch, [1]: CNode_390, [2]: ValueNode<FuncGraph> 3forward_392, [3]: ValueNode<FuncGraph> 3forward_393}
#   6: @3forward_85:CNode_394{[0]: CNode_391}
#   7: @3forward_85:CNode_395{[0]: ValueNode<FuncGraph> 4forward_86, [1]: CNode_394}
#   8: @3forward_85:CNode_397{[0]: ValueNode<Primitive> Return, [1]: CNode_395}
#   9: @3forward_396:ops{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> ops}
#  10: @3forward_396:self._update_causal_mask{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> _update_causal_mask}
#  11: @3forward_396:self.layers{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> layers}
#  12: @3forward_396:self.norm{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> norm}
#  13: @3forward_396:tuple{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> tuple}
#  14: @3forward_396:BaseModelOutputWithPast{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> BaseModelOutputWithPast}


subgraph attr:
after_block : 1
subgraph instance: 4forward_86 : 0x165fdad40
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @4forward_86 parent: [subgraph @3forward_85](%para82_) {
  %1(CNode_398) = resolve(Ast, is_)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:532/        if cache_position is None:/
  %2(CNode_399) = $(forward_79):extract_keyword_arg("cache_position", %para79_cache_position)
      : (<String, NoShape>, <Keyword[key : cache_position, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %3(CNode_400) = %1(%2, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:532/        if cache_position is None:/
  %4(CNode_401) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:532/        if cache_position is None:/
  %5(CNode_402) = Switch(%4, @4forward_403, @4forward_404)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:532/        if cache_position is None:/
  %6(CNode_405) = %5()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:532/        if cache_position is None:/

#------------------------> 34
  %7(CNode_406) = call @5forward_87(%6)
      : (<Tensor[Int64], (128)>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:532/        if cache_position is None:/
}
# Order:
#   1: @4forward_86:CNode_398{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_}
#   2: @4forward_86:CNode_400{[0]: CNode_398, [1]: CNode_399, [2]: ValueNode<None> None}
#   3: @4forward_86:CNode_401{[0]: ValueNode<Primitive> Cond, [1]: CNode_400, [2]: ValueNode<BoolImm> false}
#   4: @4forward_407:ops{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> ops}
#   5: @4forward_86:CNode_402{[0]: ValueNode<Primitive> Switch, [1]: CNode_401, [2]: ValueNode<FuncGraph> 4forward_403, [3]: ValueNode<FuncGraph> 4forward_404}
#   6: @4forward_86:CNode_405{[0]: CNode_402}
#   7: @4forward_86:CNode_406{[0]: ValueNode<FuncGraph> 5forward_87, [1]: CNode_405}
#   8: @4forward_86:CNode_408{[0]: ValueNode<Primitive> Return, [1]: CNode_406}
#   9: @4forward_407:self._update_causal_mask{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> _update_causal_mask}
#  10: @4forward_407:self.layers{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> layers}
#  11: @4forward_407:self.norm{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> norm}
#  12: @4forward_407:tuple{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> tuple}
#  13: @4forward_407:BaseModelOutputWithPast{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> BaseModelOutputWithPast}


subgraph attr:
after_block : 1
subgraph instance: 5forward_87 : 0x16601a100
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @5forward_87 parent: [subgraph @4forward_86](%para83_) {
  %1(CNode_409) = resolve(Ast, is_)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:537/        if position_ids is None:/
  %2(CNode_410) = $(forward_79):extract_keyword_arg("position_ids", %para72_position_ids)
      : (<String, NoShape>, <Keyword[key : position_ids, value : None], NoShape>) -> (<None, NoShape>)
      #scope: (Default)
  %3(CNode_411) = %1(%2, None)
      : (<None, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:537/        if position_ids is None:/
  %4(CNode_412) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:537/        if position_ids is None:/
  %5(CNode_413) = Switch(%4, @5forward_414, @5forward_415)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:537/        if position_ids is None:/
  %6(CNode_416) = %5()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:537/        if position_ids is None:/

#------------------------> 35
  %7(CNode_417) = call @6forward_88(%6)
      : (<Tensor[Int64], (1, 128)>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:537/        if position_ids is None:/
}
# Order:
#   1: @5forward_87:CNode_409{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> Ast: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> is_}
#   2: @5forward_87:CNode_411{[0]: CNode_409, [1]: CNode_410, [2]: ValueNode<None> None}
#   3: @5forward_87:CNode_412{[0]: ValueNode<Primitive> Cond, [1]: CNode_411, [2]: ValueNode<BoolImm> false}
#   4: @5forward_87:CNode_413{[0]: ValueNode<Primitive> Switch, [1]: CNode_412, [2]: ValueNode<FuncGraph> 5forward_414, [3]: ValueNode<FuncGraph> 5forward_415}
#   5: @5forward_87:CNode_416{[0]: CNode_413}
#   6: @5forward_87:CNode_417{[0]: ValueNode<FuncGraph> 6forward_88, [1]: CNode_416}
#   7: @5forward_87:CNode_418{[0]: ValueNode<Primitive> Return, [1]: CNode_417}
#   8: @5forward_419:self._update_causal_mask{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> _update_causal_mask}
#   9: @5forward_419:self.layers{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> layers}
#  10: @5forward_419:self.norm{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> norm}
#  11: @5forward_419:tuple{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> tuple}
#  12: @5forward_419:BaseModelOutputWithPast{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> BaseModelOutputWithPast}


subgraph attr:
after_block : 1
subgraph instance: 6forward_88 : 0x16601f4a0
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @6forward_88 parent: [subgraph @5forward_87](%para84_) {
  %1(CNode_331) = $(forward_79):resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:502/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %2(CNode_333) = $(forward_79):extract_keyword_arg("output_hidden_states", %para77_output_hidden_states)
      : (<String, NoShape>, <Keyword[key : output_hidden_states, value : Bool], NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
  %3(CNode_332) = $(forward_79):%1(%2, None)
      : (<Bool, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:502/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %4(CNode_334) = $(forward_79):Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:502/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %5(CNode_335) = $(forward_79):Switch(%4, @forward_336, @forward_337)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:502/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %6(output_hidden_states) = $(forward_79):%5()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:502/            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states/
  %7(CNode_420) = Cond(%6, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:547/        all_hidden_states = () if output_hidden_states else None/
  %8(CNode_421) = Switch(%7, @6forward_422, @6forward_423)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:547/        all_hidden_states = () if output_hidden_states else None/
  %9(all_hidden_states) = %8()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:547/        all_hidden_states = () if output_hidden_states else None/
  %10(CNode_324) = $(forward_79):resolve(Ast, is_not)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:500/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %11(CNode_326) = $(forward_79):extract_keyword_arg("output_attentions", %para76_output_attentions)
      : (<String, NoShape>, <Keyword[key : output_attentions, value : Bool], NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
  %12(CNode_325) = $(forward_79):%10(%11, None)
      : (<Bool, NoShape>, <None, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:500/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %13(CNode_327) = $(forward_79):Cond(%12, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:500/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %14(CNode_328) = $(forward_79):Switch(%13, @forward_329, @forward_330)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:500/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %15(output_attentions) = $(forward_79):%14()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:500/        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions/
  %16(CNode_424) = Cond(%15, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:548/        all_self_attns = () if output_attentions else None/
  %17(CNode_425) = Switch(%16, @6forward_426, @6forward_427)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:548/        all_self_attns = () if output_attentions else None/
  %18(all_self_attns) = %17()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:548/        all_self_attns = () if output_attentions else None/

#------------------------> 36
  %19(CNode_428) = call @6forward_89(I64(0), %para82_inputs_embeds, %9, %18, None)
      : (<Int64, NoShape>, <Tensor[Float32], (3, 128, 2048)>, <None, NoShape>, <None, NoShape>, <None, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/core/nn/modules/module.py:390/            return self.forward(*args, **kwargs)/
  Return(%19)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551/        for decoder_layer in self.layers:/
}
# Order:
#   1: @6forward_429:self._update_causal_mask{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> _update_causal_mask}
#   2: @6forward_429:CNode_430{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   3: @6forward_429:CNode_431{[0]: CNode_430, [1]: param_attention_mask, [2]: param_inputs_embeds, [3]: param_cache_position, [4]: param_past_key_values, [5]: output_attentions}
#   4: @6forward_88:causal_mask{[0]: CNode_364, [1]: CNode_432, [2]: param_inputs_embeds, [3]: param_cache_position, [4]: param_past_key_values, [5]: output_attentions}
#   5: @6forward_88:CNode_420{[0]: ValueNode<Primitive> Cond, [1]: output_hidden_states, [2]: ValueNode<BoolImm> false}
#   6: @6forward_88:CNode_421{[0]: ValueNode<Primitive> Switch, [1]: CNode_420, [2]: ValueNode<FuncGraph> 6forward_422, [3]: ValueNode<FuncGraph> 6forward_423}
#   7: @6forward_88:all_hidden_states{[0]: CNode_421}
#   8: @6forward_88:CNode_424{[0]: ValueNode<Primitive> Cond, [1]: output_attentions, [2]: ValueNode<BoolImm> false}
#   9: @6forward_88:CNode_425{[0]: ValueNode<Primitive> Switch, [1]: CNode_424, [2]: ValueNode<FuncGraph> 6forward_426, [3]: ValueNode<FuncGraph> 6forward_427}
#  10: @6forward_88:all_self_attns{[0]: CNode_425}
#  11: @6forward_88:CNode_433{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> len}
#  12: @6forward_88:CNode_434{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> getitem}
#  13: @6forward_88:CNode_435{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> iter}
#  14: @6forward_429:self.layers{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> layers}
#  15: @6forward_88:CNode_436{[0]: CNode_433, [1]: CNode_365}
#  16: @6forward_88:CNode_437{[0]: ValueNode<Primitive> Return, [1]: CNode_428}
#  17: @6forward_429:self.norm{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> norm}
#  18: @6forward_429:tuple{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> tuple}
#  19: @6forward_429:BaseModelOutputWithPast{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> BaseModelOutputWithPast}
#  20: @6forward_88:CNode_428{[0]: ValueNode<FuncGraph> 6forward_89, [1]: ValueNode<Int64Imm> 0, [2]: param_inputs_embeds, [3]: all_hidden_states, [4]: all_self_attns, [5]: ValueNode<None> None}


subgraph attr:
subgraph instance: 6forward_89 : 0x165fffd30
# In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:487/    def forward(/
subgraph @6forward_89 parent: [subgraph @6forward_88](%para85_, %para86_, %para87_, %para88_, %para89_) {
  %1(CNode_433) = $(6forward_88):resolve(CommonOPS, len)
      : (<External, NoShape>, <External, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551/        for decoder_layer in self.layers:/
  %2(CNode_365) = $(forward_79):resolve(ClassMember, layers)
      : (<External, NoShape>, <External, NoShape>) -> (<Class, NoShape>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551/        for decoder_layer in self.layers:/

#------------------------> 37
  %3(CNode_436) = $(6forward_88):%1(%2)
      : (<Class, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551/        for decoder_layer in self.layers:/
  %4(CNode_438) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para85_@CNode_90, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551/        for decoder_layer in self.layers:/
  %5(CNode_439) = Switch(%4, @6forward_440, @7forward_441)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551/        for decoder_layer in self.layers:/
  %6(CNode_442) = %5()
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551/        for decoder_layer in self.layers:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/site-packages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:551/        for decoder_layer in self.layers:/
}
# Order:
#   1: @6forward_89:CNode_438{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.443, [1]: param_@CNode_90, [2]: CNode_436}
#   2: @6forward_89:CNode_439{[0]: ValueNode<Primitive> Switch, [1]: CNode_438, [2]: ValueNode<FuncGraph> 6forward_440, [3]: ValueNode<FuncGraph> 7forward_441}
#   3: @6forward_89:CNode_442{[0]: CNode_439}
#   4: @6forward_89:CNode_444{[0]: ValueNode<Primitive> Return, [1]: CNode_442}
#   5: @6forward_445:self.norm{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> ClassMember: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2..<Qwen2Model::140177699729360>', [2]: ValueNode<Symbol> norm}
#   6: @6forward_445:tuple{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> tuple}
#   7: @6forward_445:BaseModelOutputWithPast{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> SymbolStr: 'Namespace:mindnlp.transformers.models.qwen2.modeling_qwen2', [2]: ValueNode<Symbol> BaseModelOutputWithPast}


# ===============================================================================================
# The total of function graphs in evaluation stack: 38/42 (Ignored 4 internal frames).
# ===============================================================================================


# ===============================================================================================
# The rest function graphs are the following:
# ===============================================================================================
subgraph attr:
subgraph instance: compute_ce_loss_105 : 0x165acae70
# In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:133/    def compute_ce_loss(logits, labels):/
subgraph @compute_ce_loss_105(%para90_logits, %para91_labels) {
  %1(loss_fct) = ClassType()
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:134/        loss_fct = CrossEntropyLossForCausalLM()/
  %2(loss) = %1(%para90_logits, %para91_labels)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:136/        loss = loss_fct(logits, labels)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /home/zjj/xjd/huawei-ict-2024/ChatStyle/train_simple.py:138/        return loss/
}
# Order:
#   1: @compute_ce_loss_105:loss_fct{[0]: ValueNode<ClassType> class 'losser.CrossEntropyLossForCausalLM'}
#   2: @compute_ce_loss_105:loss{[0]: loss_fct, [1]: param_logits, [2]: param_labels}
#   3: @compute_ce_loss_105:CNode_446{[0]: ValueNode<Primitive> Return, [1]: loss}


