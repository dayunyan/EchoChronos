import logging
import os
from typing import List, Dict, Tuple
import mindspore as ms
from mindnlp.peft import PeftModel, PeftConfig, LoraConfig, get_peft_model
from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer
import streamlit as st
import requests
import base64

from RAG import ConfigLoader, EmbeddingModelCreator, RetrieverCreator

from llm.TorchModel_lora import Torch_Lora_LLM

from utils.yamlparam import YAMLParamHandler


os.environ["CUDA_VISIBLE_DEVICES"] = "0,1"  # æŒ‡å®šæ˜¾å¡

yaml_path = "./examples/infer_qwen2_lora_fp32_ms.yaml"
yaml_data = YAMLParamHandler(yaml_path).get_yaml_params()
rag_config = yaml_data.get("rag_config", {})


@st.cache_resource
def load_config(_config):
    return ConfigLoader(_config)


@st.cache_resource
def load_embedding(_config):
    embedding_creator = EmbeddingModelCreator(_config)
    embedding_model = embedding_creator.create_embedding_model()
    return embedding_model


# @st.cache_resource
def load_vecDB(_config, embedding_model):
    retriever_creator = RetrieverCreator(_config, embedding_model)
    return retriever_creator


@st.cache_resource
def load_Qwen2_7b_llm(_config):
    _config = _config["model"]
    model_name_or_path = _config.get("model_path", "model_name")
    model_kwargs = _config.get("model_kwargs", {})
    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, **model_kwargs)
    adapter_path = _config.get("adapter_path", "adapter_name")
    lora_config = LoraConfig.from_pretrained(adapter_path)
    model = get_peft_model(model, lora_config)
    model.eval()
    return tokenizer, model


def format_docs(docs, wiki_docs=None):
    ans = "ä»å¤ç±ä¸­æ£€ç´¢åˆ°çš„ä¿¡æ¯å¦‚ä¸‹ï¼š\n\n"
    for id, doc in enumerate(docs):
        ans += f"{id+1}. {doc.page_content}\n\n"
    if wiki_docs is not None:
        ans += "ä»ç»´åŸºç™¾ç§‘ä¸­æ£€ç´¢åˆ°çš„ä¿¡æ¯å¦‚ä¸‹ï¼š\n\n"
        ans += f'{len(docs)+1}. {wiki_docs[0].metadata["summary"]}\n\n'
    # print(f'æ£€ç´¢åˆ°çš„ä¿¡æ¯æœ‰ï¼š{ans}')
    return ans


def get_prompt(
    msgs: List[Dict],
    source: str = "è¥¿æ¸¸è®°",
    role: str = "å­™æ‚Ÿç©º",
    has_RAG=True,
    rag_info: str = "",
):
    text = ""
    for i in range(len(msgs)):
        if msgs[i]["role"] == "system":
            text += prompt_system.format(msgs[i]["content"])
        elif msgs[i]["role"] == "user":
            retrieved_info = rag_info if has_RAG else ""
            if i == 1:
                if i == len(msgs) - 1:
                    user_input = """å‡å¦‚ä½ æ˜¯<{source}>ä¸­çš„{role}ï¼Œè¯·ä¸æˆ‘å¯¹è¯ã€‚\n
                    {retrieved_info}\n
                    å‚è€ƒä»¥ä¸Šä¿¡æ¯ï¼Œä¸æˆ‘å¯¹è¯ã€‚\n
                    {query}""".format(
                        source=source,
                        role=role,
                        retrieved_info=retrieved_info,
                        query=msgs[i]["content"],
                    )
                else:
                    user_input = """å‡å¦‚ä½ æ˜¯<{source}>ä¸­çš„{role}ï¼Œè¯·ä¸æˆ‘å¯¹è¯ã€‚\n
                    {query}""".format(
                        source=source,
                        role=role,
                        query=msgs[i]["content"],
                    )
            else:
                if i == len(msgs) - 1:
                    user_input = """{retrieved_info}\n
                    å‚è€ƒä»¥ä¸Šä¿¡æ¯ï¼Œä¸æˆ‘å¯¹è¯ã€‚\n
                    {query}""".format(
                        retrieved_info=retrieved_info,
                        query=msgs[i]["content"],
                    )
                else:
                    user_input = """{query}""".format(
                        query=msgs[i]["content"],
                    )

            text += prompt_user.format(user_input)
        else:
            text += prompt_assistant.format(msgs[i]["content"])
    text += f"{ROLE_DICT[source][role]}é“ï¼š"

    return text


ROLE_DICT = {
    "è¥¿æ¸¸è®°": {
        "å­™æ‚Ÿç©º": "æ‚Ÿç©º",
        "å”åƒ§": "å”åƒ§",
        "çŒªå…«æˆ’": "å…«æˆ’",
        "æ²™åƒ§": "æ²™åƒ§",
    },
    "ä¸‰å›½æ¼”ä¹‰": {
        "åˆ˜å¤‡": "ç„å¾·",
        "å…³ç¾½": "äº‘é•¿",
        "å¼ é£": "ç¿¼å¾·",
        "æ›¹æ“": "å­Ÿå¾·",
        "è¯¸è‘›äº®": "å­”æ˜",
    },
    "æ°´æµ’ä¼ ": {
        "å®‹æ±Ÿ": "å®‹å…¬æ˜",
        "å¢ä¿Šä¹‰": "ç‰éº’éºŸ",
        "å´ç”¨": "æ™ºå¤šæ˜Ÿ",
        "æ—å†²": "è±¹å­å¤´",
    },
    "çº¢æ¥¼æ¢¦": {
        "è´¾å®ç‰": "å®ç‰",
        "æ—é»›ç‰": "é»›ç‰",
        "è–›å®é’—": "å®é’—",
        "ç‹ç†™å‡¤": "å‡¤å§",
    },
}

prompt_system = "<|im_start|>system\n{}<|im_end|>\n"
prompt_user = "<|im_start|>user\n{}<|im_end|>\n<|im_start|>assistant\n"
prompt_assistant = "{}<|im_end|>\n"

# åˆå§‹åŒ–å†å²å¯¹è¯è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system",
            "content": "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.",
        },
    ]

# if 'retrieve' not in st.session_state:
#     st.session_state.retrieve = None

# def set_retrieve(info):
#     st.session_state.retrieve = info

if "audio" not in st.session_state:
    st.session_state.audio = []


def append_audio(audio):
    st.session_state.audio.append(audio)


# è®¾ç½®æœåŠ¡å™¨åœ°å€å’Œç«¯å£
server_url = (
    yaml_data["runner"].get("tts_server")
    if yaml_data["runner"].get("has_tts", False)
    else None
)


# å®šä¹‰ç”ŸæˆéŸ³é¢‘çš„å‡½æ•°
def generate_audio(character, text):
    # è®¾ç½®è¦ä¼ é€’çš„å‚æ•°
    prompt_language = "ä¸­æ–‡"  # å‚è€ƒæ–‡æœ¬çš„è¯­è¨€
    text_language = "ä¸­æ–‡"  # ç›®æ ‡æ–‡æœ¬çš„è¯­è¨€
    how_to_cut = "æŒ‰ä¸­æ–‡å¥å·ã€‚åˆ‡"  # æ–‡æœ¬åˆ‡åˆ†æ–¹å¼
    top_k = 20  # Top-K å‚æ•°
    top_p = 0.8  # Top-P å‚æ•°
    temperature = 0.6  # æ¸©åº¦å‚æ•°
    ref_free = False  # æ˜¯å¦ä½¿ç”¨å‚è€ƒéŸ³é¢‘

    # å‡†å¤‡POSTè¯·æ±‚çš„payload
    data = {
        "character": character,
        "prompt_language": prompt_language,
        "text": text,
        "text_language": text_language,
        "how_to_cut": how_to_cut,
        "top_k": top_k,
        "top_p": top_p,
        "temperature": temperature,
        "ref_free": ref_free,
    }

    # å‘é€POSTè¯·æ±‚
    response = requests.post(server_url, data=data)

    if response.status_code == 200:
        # è¿”å›çš„éŸ³é¢‘æ–‡ä»¶å†…å®¹
        audio_content = response.content
        return audio_content
    else:
        return f"Error: {response.status_code}, {response.text}"


# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="EchoChronos", layout="wide", page_icon="ğŸ¦œ")

st.sidebar.title("Configuration")
temperature = st.sidebar.slider("Temperature:", 0.01, 1.0, 1.0)
top_k = st.sidebar.slider("Top K:", 1, 50, 10)
top_p = st.sidebar.slider("Top P:", 0.01, 1.0, 0.7)
numk = st.sidebar.slider("Number of retrieved documents:", 0, 10, 3)
max_new_tokens = st.sidebar.slider("Max generation tokens:", 1, 2048, 512)


# è‡ªå®šä¹‰CSSæ ·å¼ï¼Œè®¾ç½®èŠå¤©æ°”æ³¡çš„å¤–è§‚
st.markdown(
    """
    <style>
        .chat-bubble {
            display: inline-block;
            padding: 10px;
            border-radius: 20px;
            margin: 5px 0;
            max-width: 60%;
            font-size: 22px;
        }
        .user {
            background-color: #DCF8C6;
            text-align: left;
        }
        .assistant {
            background-color: #FFA500;
            text-align: left;
        }
        .chat-container {
            display: flex;
            flex-direction: column;
            align-items: flex-start;
            justify-content: flex-start;
        }
        .audio-container {
            margin-left: 0px;  /* æ§åˆ¶éŸ³é¢‘æ§ä»¶çš„ç¼©è¿›ä½ç½® */
            margin-top: 5px;
        }
       
    </style>
""",
    unsafe_allow_html=True,
)

# æ„å»ºé¡µé¢
st.title("EchoChronosğŸ¦œ")
st.write(
    f"<span style='font-size: 22px; color: #FF6347;'>å¯¹è¯ä¹‹å‰è®°å¾—å…ˆé€‰æ‹©å¯¹è¯çš„è§’è‰²å‘¦â¤ï¸~~~</span>",
    unsafe_allow_html=True,
)

col1, col2 = st.columns(2)
with col1:
    source = st.selectbox(
        "é€‰æ‹©ä¹¦ç±", ["çº¢æ¥¼æ¢¦", "è¥¿æ¸¸è®°", "ä¸‰å›½æ¼”ä¹‰", "æ°´æµ’ä¼ "], key="source"
    )
with col2:
    character = st.selectbox(
        "é€‰æ‹©è§’è‰²",
        ["æ—é»›ç‰", "è´¾å®ç‰", "å­™æ‚Ÿç©º", "çŒªå…«æˆ’", "è¯¸è‘›äº®", "æ›¹æ“", "æ—å†²", "é²æ™ºæ·±"],
        key="char",
    )

# ç”¨æˆ·è¾“å…¥æ¡†
# query = st.text_area("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š", height=100)

# LangChain é…ç½®
template = """è¯·ä»…æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„å‡è®¾æˆ–çŸ¥è¯†: \n
    {retrieved_info}\n
    è¯·å›ç­”ä»¥ä¸‹é—®é¢˜: {query}\n"""

config = load_config(rag_config)
tokenizer, model = load_Qwen2_7b_llm(yaml_data)
embedding = load_embedding(config)

vecDB = load_vecDB(config, embedding)

# prompt = PromptTemplate(template=template, input_variables=["query", "retrieved_info"])

log_level = yaml_data["global"].get("log_level", "INFO")
logging.basicConfig(
    level=log_level, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# æ˜¾ç¤ºå¯¹è¯
def display_messages():
    idx = 0
    for message in st.session_state.messages:
        # ç”¨æˆ·æ¶ˆæ¯
        if message["role"] == "user":
            col1, col2 = st.columns([1, 15])
            with col1:
                st.markdown(
                    f"<p style='font-size: 36px; color: gray;'> {'ğŸ¤“'}</p>",
                    unsafe_allow_html=True,
                )  # æ˜¾ç¤ºè¡¨æƒ…
            with col2:
                st.markdown(
                    f"<div class='chat-bubble user'>{message['content']}</div>",
                    unsafe_allow_html=True,
                )

        # å¤§æ¨¡å‹å›ç­”
        elif message["role"] == "assistant":
            col1, col2 = st.columns([1, 15])
            with col1:
                st.markdown(
                    f"<p style='font-size: 36px; color: gray;'> {'ğŸ¤–'}</p>",
                    unsafe_allow_html=True,
                )  # æ˜¾ç¤ºè¡¨æƒ…
            with col2:
                st.markdown(
                    f"<div class='chat-bubble assistant'>{message['content']}</div>",
                    unsafe_allow_html=True,
                )

            col1, col2 = st.columns([1, 15])
            with col1:
                st.markdown(
                    f"<p style='font-size: 36px; color: gray;'> {'ğŸ¤–'}</p>",
                    unsafe_allow_html=True,
                )  # æ˜¾ç¤ºè¡¨æƒ…
            with col2:
                # å°†éŸ³é¢‘å­—èŠ‚æ•°æ®ç¼–ç ä¸ºbase64
                audio_base64 = base64.b64encode(st.session_state.audio[idx]).decode(
                    "utf-8"
                )
                audio_url = f"data:audio/wav;base64,{audio_base64}"
                st.markdown(
                    f'<div class="audio-container"><audio controls><source src="{audio_url}" type="audio/wav"></audio></div>',
                    unsafe_allow_html=True,
                )
                idx += 1


# è·å–ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›å¤
def user_input():
    query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š", "")
    col1, col2 = st.columns([0.1, 1])
    with col1:
        send = st.button("å‘é€", key="send")
    with col2:
        # clean = st.button("é‡æ–°å¼€å§‹å¯¹è¯", on_click=restart, args=[], key="clean")
        clean = st.button("é‡æ–°å¼€å§‹")

    if clean:
        st.session_state.messages.clear()
        st.session_state.messages = [
            {
                "role": "system",
                "content": "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.",
            },
        ]
        st.session_state.audio.clear()

        st.rerun()

    if send:
        with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
            st.session_state.messages.append({"role": "user", "content": query})

            template_retrieved = "åœ¨{source}ä¸­, é’ˆå¯¹{character}è¿™ä¸ªè§’è‰²çš„æé—®ï¼š{query}"
            retrieved_dict = {"source": source, "character": character, "query": query}

            search_type = config.get(
                "langchain_modules.retrievers.vector_retriever.retrieval_type",
                "similarity",
            )
            search_kwargs = config.get(
                "langchain_modules.retrievers.vector_retriever.search_kwargs", {}
            )
            search_kwargs["k"] = numk

            retriever = vecDB.vector_store.as_retriever(
                search_type=search_type, search_kwargs=search_kwargs
            )

            retrieved_docs = retriever.invoke(
                template_retrieved.format(**retrieved_dict)
            )

            formatted_docs = format_docs(retrieved_docs)

            # logger.info(formatted_docs)

            inputs = get_prompt(
                st.session_state.messages,
                source=source,
                role=character,
                has_RAG=True,
                rag_info=formatted_docs,
            )

            # rag_res = llm(input)
            model_inputs = tokenizer([inputs], return_tensors="ms")
            generate_kwargs = yaml_data["model"].get("generate_kwargs", {})
            generated_ids = model.generate(
                input_ids=model_inputs.input_ids,
                **generate_kwargs,
            )
            generated_ids = [
                output_ids[len(input_ids) :]
                for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
            ]
            rag_res = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]

            st.session_state.messages.append(
                {"role": "assistant", "content": rag_res.strip(" ").strip("â€œâ€")}
            )

            char_dict = {
                "æ—é»›ç‰": "lindaiyu",
                "è´¾å®ç‰": "jiabaoyu",
                "è¯¸è‘›äº®": "zhugeliang",
                "æ›¹æ“": "caocao",
                "å­™æ‚Ÿç©º": "sunwukong",
                "çŒªå…«æˆ’": "zhubajie",
                "æ—å†²": "linchong",
                "é²æ™ºæ·±": "luzhishen",
            }
            # ç”ŸæˆéŸ³é¢‘
            audio_content = generate_audio(char_dict[character], rag_res)

            append_audio(audio_content)

            st.rerun()


# è°ƒç”¨æ˜¾ç¤ºå‡½æ•°
display_messages()
user_input()
