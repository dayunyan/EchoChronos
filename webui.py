import streamlit as st
import sys

# from utils.argparser import get_args, check_args
from utils.yamlparam import YAMLParamHandler
from managers.runner import RunnerManager


# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="EchoChronos", layout="wide", page_icon="ğŸ¦œ")

st.sidebar.title("Configuration")
temperature = st.sidebar.slider("Temperature:", 0.01, 1.0, 1.0)
numk = st.sidebar.slider("Number of retrieved documents:", 0, 10, 3)
max_new_tokens = st.sidebar.slider("Max generation tokens:", 1, 2048, 512)


# è‡ªå®šä¹‰CSSæ ·å¼ï¼Œè®¾ç½®èŠå¤©æ°”æ³¡çš„å¤–è§‚
st.markdown(
    """
    <style>
        .chat-bubble {
            display: inline-block;
            padding: 10px;
            border-radius: 20px;
            margin: 5px 0;
            max-width: 60%;
            font-size: 22px;
        }
        .user {
            background-color: #DCF8C6;
            text-align: left;
        }
        .assistant {
            background-color: #FFA500;
            text-align: left;
        }
        .chat-container {
            display: flex;
            flex-direction: column;
            align-items: flex-start;
            justify-content: flex-start;
        }
        .audio-container {
            margin-left: 0px;  /* æ§åˆ¶éŸ³é¢‘æ§ä»¶çš„ç¼©è¿›ä½ç½® */
            margin-top: 5px;
        }
       
    </style>
""",
    unsafe_allow_html=True,
)

# æ„å»ºé¡µé¢
st.title("EchoChronosğŸ¦œ")
st.write(
    f"<span style='font-size: 22px; color: #FF6347;'>å¯¹è¯ä¹‹å‰è®°å¾—å…ˆé€‰æ‹©å¯¹è¯çš„è§’è‰²å‘¦â¤ï¸~~~</span>",
    unsafe_allow_html=True,
)

col1, col2 = st.columns(2)
with col1:
    book = st.selectbox(
        "é€‰æ‹©ä¹¦ç±", ["çº¢æ¥¼æ¢¦", "è¥¿æ¸¸è®°", "ä¸‰å›½æ¼”ä¹‰", "æ°´æµ’ä¼ "], key="book"
    )
with col2:
    character = st.selectbox(
        "é€‰æ‹©è§’è‰²",
        ["æ—é»›ç‰", "è´¾å®ç‰", "å­™æ‚Ÿç©º", "çŒªå…«æˆ’", "è¯¸è‘›äº®", "æ›¹æ“", "æ—å†²", "é²æ™ºæ·±"],
        key="char",
    )


# æ˜¾ç¤ºå¯¹è¯
def display_messages():
    idx = 0
    for message in st.session_state.messages:
        # ç”¨æˆ·æ¶ˆæ¯
        if message["role"] == "user":
            col1, col2 = st.columns([1, 15])
            with col1:
                st.markdown(
                    f"<p style='font-size: 36px; color: gray;'> {'ğŸ¤“'}</p>",
                    unsafe_allow_html=True,
                )  # æ˜¾ç¤ºè¡¨æƒ…
            with col2:
                st.markdown(
                    f"<div class='chat-bubble user'>{message['content']}</div>",
                    unsafe_allow_html=True,
                )

        # å¤§æ¨¡å‹å›ç­”
        elif message["role"] == "assistant":
            col1, col2 = st.columns([1, 15])
            with col1:
                st.markdown(
                    f"<p style='font-size: 36px; color: gray;'> {'ğŸ¤–'}</p>",
                    unsafe_allow_html=True,
                )  # æ˜¾ç¤ºè¡¨æƒ…
            with col2:
                st.markdown(
                    f"<div class='chat-bubble assistant'>{message['content']}</div>",
                    unsafe_allow_html=True,
                )

            col1, col2 = st.columns([1, 15])
            with col1:
                st.markdown(
                    f"<p style='font-size: 36px; color: gray;'> {'ğŸ¤–'}</p>",
                    unsafe_allow_html=True,
                )  # æ˜¾ç¤ºè¡¨æƒ…
            with col2:
                # å°†éŸ³é¢‘å­—èŠ‚æ•°æ®ç¼–ç ä¸ºbase64
                audio_base64 = base64.b64encode(st.session_state.audio[idx]).decode(
                    "utf-8"
                )
                audio_url = f"data:audio/wav;base64,{audio_base64}"
                st.markdown(
                    f'<div class="audio-container"><audio controls><source src="{audio_url}" type="audio/wav"></audio></div>',
                    unsafe_allow_html=True,
                )
                idx += 1


# è·å–ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå›å¤
def user_input():
    query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š", "")
    col1, col2 = st.columns([0.1, 1])
    with col1:
        send = st.button("å‘é€", key="send")
    with col2:
        # clean = st.button("é‡æ–°å¼€å§‹å¯¹è¯", on_click=restart, args=[], key="clean")
        clean = st.button("é‡æ–°å¼€å§‹")

    if clean:
        st.session_state.messages.clear()
        st.session_state.messages = [
            {
                "role": "system",
                "content": "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.",
            },
        ]
        st.session_state.audio.clear()

        st.rerun()

    if send:
        with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
            st.session_state.messages.append({"role": "user", "content": query})

            template_retrieved = "åœ¨{book}ä¸­, é’ˆå¯¹{character}è¿™ä¸ªè§’è‰²çš„æé—®ï¼š{query}"
            retrieved_dict = {"book": book, "character": character, "query": query}

            search_type = config.get(
                "langchain_modules.retrievers.vector_retriever.retrieval_type",
                "similarity",
            )
            search_kwargs = config.get(
                "langchain_modules.retrievers.vector_retriever.search_kwargs", {}
            )
            search_kwargs["k"] = numk

            retriever = vecDB.vector_store.as_retriever(
                search_type=search_type, search_kwargs=search_kwargs
            )

            retrieved_docs = retriever.invoke(
                template_retrieved.format(**retrieved_dict)
            )

            formatted_docs = format_docs(retrieved_docs)

            # logger.info(formatted_docs)

            input = get_prompt(
                st.session_state.messages,
                book=book,
                role=character,
                has_RAG=True,
                rag_info=formatted_docs,
            )

            # rag_res = llm(input)
            model_inputs = llm.tokenizer([input], return_tensors="pt").to("cuda")
            generated_ids = llm.model.generate(
                model_inputs.input_ids,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
            )
            generated_ids = [
                output_ids[len(input_ids) :]
                for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
            ]
            rag_res = llm.tokenizer.batch_decode(
                generated_ids, skip_special_tokens=True
            )[0]

            st.session_state.messages.append(
                {"role": "assistant", "content": rag_res.strip(" ").strip("â€œâ€")}
            )

            char_dict = {
                "æ—é»›ç‰": "lindaiyu",
                "è´¾å®ç‰": "jiabaoyu",
                "è¯¸è‘›äº®": "zhugeliang",
                "æ›¹æ“": "caocao",
                "å­™æ‚Ÿç©º": "sunwukong",
                "çŒªå…«æˆ’": "zhubajie",
                "æ—å†²": "linchong",
                "é²æ™ºæ·±": "luzhishen",
            }
            # ç”ŸæˆéŸ³é¢‘
            audio_content = generate_audio(char_dict[character], rag_res)

            append_audio(audio_content)

            st.rerun()


# è°ƒç”¨æ˜¾ç¤ºå‡½æ•°
display_messages()
user_input()
